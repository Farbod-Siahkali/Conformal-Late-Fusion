{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c828f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:02<00:00, 67.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "\n",
      "=== Simulation 1/10 ===\n",
      "\n",
      "  -> K = 4 (ablation target)\n",
      "    [View 1/4] training...\n",
      "  epoch 25/75\n",
      "  epoch 50/75\n",
      "  epoch 75/75\n",
      "    [View 2/4] training...\n",
      "  epoch 25/75\n",
      "  epoch 50/75\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CIFAR-100 ablation study (matched to your MAIN CIFAR-100 script):\n",
    "\n",
    "Goal: vary fusion-train size n_t as a fraction of baseline n_t (fusion-train split),\n",
    "and plot (1) coverage and (2) average set size vs n_t fraction, for K=4.\n",
    "\n",
    "MATCHING GUARANTEE (practically):\n",
    "- For K=4 and nt_frac=1.0, CF (conformal fusion LR on [p;prob]) and AdjF should match the MAIN CIFAR-100\n",
    "  script’s K=4 behavior, because we:\n",
    "  (i) use the SAME per-view model + SAME train_model,\n",
    "  (ii) use the SAME data splits + seeds,\n",
    "  (iii) use SAME feature construction and conformalization.\n",
    "\n",
    "Outputs:\n",
    "  - cifar100_ablation_ntfrac_results.csv\n",
    "  - cifar100_ablation_ntfrac_agg_K4.csv\n",
    "  - cifar100_ablation_ntfrac_cifar100_K4.pdf  (and .png)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =========================\n",
    "# Plot style (NO seaborn)\n",
    "# =========================\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import scienceplots  # noqa: F401\n",
    "    plt.style.use([\"science\", \"no-latex\"])\n",
    "except Exception as e:\n",
    "    print(\"[WARN] scienceplots not found or style failed; using default matplotlib style.\", e)\n",
    "\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "mpl.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 8,\n",
    "        \"axes.titlesize\": 9,\n",
    "        \"axes.labelsize\": 8,\n",
    "        \"xtick.labelsize\": 7,\n",
    "        \"ytick.labelsize\": 7,\n",
    "        \"legend.fontsize\": 6,\n",
    "        \"lines.linewidth\": 1.0,\n",
    "        \"axes.linewidth\": 0.5,\n",
    "    }\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Config (MATCH your CIFAR-100 experiment params)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class AblationConfig100:\n",
    "    # core (match CIFAR-100 experiment)\n",
    "    alpha: float = 0.1\n",
    "    num_classes: int = 100\n",
    "    num_simulations: int = 10\n",
    "\n",
    "    # training (match CIFAR-100 experiment)\n",
    "    epochs_per_view: int = 75\n",
    "    lr: float = 1e-3\n",
    "    batch_size: int = 8192\n",
    "    max_iter_lr: int = 1000\n",
    "    train_seed_base: int = 41\n",
    "\n",
    "    # data split fractions (match CIFAR-100 experiment)\n",
    "    train_frac: float = 0.5\n",
    "    cal_frac_of_temp: float = 0.3\n",
    "    fuse_train_frac_of_rest: float = 0.7\n",
    "\n",
    "    # Ablation target\n",
    "    K_target: int = 4\n",
    "\n",
    "    # Ablation sweep\n",
    "    nt_fracs: Tuple[float, ...] = tuple(np.round(np.linspace(0.1, 1.0, 10), 2))\n",
    "\n",
    "    # Output\n",
    "    out_dir: str = \"cifar100_ablation_outputs\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Torch / Data (match CIFAR-100 experiment)\n",
    "# =============================================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "X_train_full = train_dataset.data.astype(np.float32) / 255.0\n",
    "Y_train_full = np.array(train_dataset.targets, dtype=int)\n",
    "X_test_full  = test_dataset.data.astype(np.float32) / 255.0\n",
    "Y_test_full  = np.array(test_dataset.targets, dtype=int)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Multi-view (patch) utilities (match CIFAR-100 experiment)\n",
    "# =============================================================================\n",
    "\n",
    "def split_image_into_k_patches(image: torch.Tensor, k: int) -> List[torch.Tensor]:\n",
    "    C, H, W = image.shape\n",
    "    if k == 4:\n",
    "        patches = []\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                patch = image[:, i*16:(i+1)*16, j*16:(j+1)*16]\n",
    "                patches.append(patch)\n",
    "        return patches\n",
    "    else:\n",
    "        base_width = W // k\n",
    "        remainder = W % k\n",
    "        patches, start = [], 0\n",
    "        for idx in range(k):\n",
    "            width = base_width + (1 if idx < remainder else 0)\n",
    "            patch = image[:, :, start:start+width]\n",
    "            patches.append(patch)\n",
    "            start += width\n",
    "        return patches\n",
    "\n",
    "\n",
    "class PatchesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images: np.ndarray, labels: np.ndarray, k: int, view: int):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.k = k\n",
    "        self.view = view\n",
    "        self.resize = Resize((32, 32))  # match your CIFAR-100 code\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img = self.images[idx].transpose((2, 0, 1))\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        patches = split_image_into_k_patches(img, self.k)\n",
    "        patch = patches[self.view]\n",
    "        patch = self.resize(patch)\n",
    "        y = int(self.labels[idx])\n",
    "        return patch, y\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EfficientNet-B0 per view (match CIFAR-100 experiment)\n",
    "# =============================================================================\n",
    "\n",
    "class PredictorCNN(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super().__init__()\n",
    "        self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def train_model(model: nn.Module, train_loader, num_epochs=75, lr=1e-3):\n",
    "    # match your CIFAR-100 code\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    opt  = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    for ep in range(num_epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), torch.tensor(yb, dtype=torch.long, device=device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if (ep + 1) % 25 == 0:\n",
    "            print(f\"  epoch {ep+1}/{num_epochs}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Conformal utilities (match CIFAR-100 experiment)\n",
    "# =============================================================================\n",
    "\n",
    "def compute_nonconformity_scores(model: nn.Module, loader) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    scores, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs  = F.softmax(logits, dim=1)\n",
    "            idx    = torch.arange(probs.size(0), device=probs.device)\n",
    "            true_p = probs[idx, torch.tensor(yb, dtype=torch.long, device=probs.device)]\n",
    "            s = (1.0 - true_p).detach().cpu().numpy()\n",
    "            scores.extend(s)\n",
    "            labels.extend(yb.numpy())\n",
    "    return np.asarray(scores, float), np.asarray(labels, int)\n",
    "\n",
    "\n",
    "def classwise_scores(scores: np.ndarray, labels: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for s, y in zip(scores, labels):\n",
    "        out[int(y)].append(float(s))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "\n",
    "def per_view_pvalues_and_probs(\n",
    "    model: nn.Module, class_scores: Dict[int, np.ndarray], loader, L: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    probs_all = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs  = F.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "            probs_all.append(probs)\n",
    "    probs_all = np.vstack(probs_all)  # (n, L)\n",
    "\n",
    "    n = probs_all.shape[0]\n",
    "    pvals = np.zeros((n, L), dtype=float)\n",
    "    for y in range(L):\n",
    "        cal = class_scores.get(y, np.array([], dtype=float))\n",
    "        if cal.size == 0:\n",
    "            pvals[:, y] = 1.0\n",
    "        else:\n",
    "            s_test = 1.0 - probs_all[:, y]\n",
    "            counts = np.sum(cal[:, None] >= s_test[None, :], axis=0)\n",
    "            pvals[:, y] = (1.0 + counts) / (len(cal) + 1.0)\n",
    "    return pvals, probs_all\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Fusion + baselines (match CIFAR-100 experiment)\n",
    "# =============================================================================\n",
    "\n",
    "def build_fusion_features(pvals_list: List[np.ndarray], probs_list: List[np.ndarray]) -> np.ndarray:\n",
    "    blocks = [np.hstack([pvals_list[k], probs_list[k]]) for k in range(len(pvals_list))]\n",
    "    return np.hstack(blocks)\n",
    "\n",
    "\n",
    "def fisher_fusion(P_all: np.ndarray) -> np.ndarray:\n",
    "    eps = 1e-12\n",
    "    p = np.clip(P_all, eps, 1.0)\n",
    "    T = -2 * np.sum(np.log(p), axis=0)\n",
    "    df = 2 * P_all.shape[0]\n",
    "    return 1 - chi2.cdf(T, df=df)\n",
    "\n",
    "\n",
    "def adjusted_fisher_fusion(P_train: np.ndarray, y_train: np.ndarray, P_test: np.ndarray, L: int) -> np.ndarray:\n",
    "    K, _, _ = P_train.shape\n",
    "    n_test = P_test.shape[1]\n",
    "    eps = 1e-12\n",
    "    out = np.zeros((n_test, L), dtype=float)\n",
    "    for y in range(L):\n",
    "        idx = np.where(y_train == y)[0]\n",
    "        if idx.size < 5:\n",
    "            out[:, y] = fisher_fusion(P_test)[:, y]\n",
    "            continue\n",
    "        P_cls = np.clip(P_train[:, idx, y], eps, 1.0)\n",
    "        W = -2 * np.log(P_cls)\n",
    "        Wc = W - W.mean(axis=1, keepdims=True)\n",
    "        Sigma = (Wc @ Wc.T) / max(W.shape[1] - 1, 1)\n",
    "        var_T = np.sum(Sigma)\n",
    "        if not np.isfinite(var_T) or var_T <= 0:\n",
    "            var_T = 4 * K\n",
    "        f_y = (8.0 * K * K) / var_T\n",
    "        c_y = var_T / (4 * K)\n",
    "\n",
    "        P_t = np.clip(P_test[:, :, y], eps, 1.0)\n",
    "        T_t = -2 * np.sum(np.log(P_t), axis=0)\n",
    "        out[:, y] = 1 - chi2.cdf(T_t / c_y, df=f_y)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fused_class_cal_scores(y_cal: np.ndarray, fused_probs_cal: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    s = 1.0 - fused_probs_cal[np.arange(len(y_cal)), y_cal]\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for sc, yy in zip(s, y_cal):\n",
    "        out[int(yy)].append(float(sc))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "\n",
    "def fused_p_values_from_cal(fused_probs: np.ndarray, cal_class_scores: Dict[int, np.ndarray]) -> np.ndarray:\n",
    "    n, L = fused_probs.shape\n",
    "    out = np.zeros((n, L), dtype=float)\n",
    "    for y in range(L):\n",
    "        cal = cal_class_scores.get(y, np.array([], dtype=float))\n",
    "        if cal.size == 0:\n",
    "            out[:, y] = 1.0\n",
    "        else:\n",
    "            s_test = 1.0 - fused_probs[:, y]\n",
    "            counts = np.sum(cal[:, None] >= s_test[None, :], axis=0)\n",
    "            out[:, y] = (1.0 + counts) / (len(cal) + 1.0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def evaluate_sets(P: np.ndarray, y_true: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    C = (P > alpha)\n",
    "    cov = float(np.mean(C[np.arange(len(y_true)), y_true]))\n",
    "    size = float(np.mean(C.sum(axis=1)))\n",
    "    return cov, size\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Subsampling helper (stratified)\n",
    "# =============================================================================\n",
    "\n",
    "def stratified_subsample_indices(y: np.ndarray, n_sub: int, seed: int) -> np.ndarray:\n",
    "    n = len(y)\n",
    "    n_sub = int(max(1, min(n_sub, n)))\n",
    "    idx_all = np.arange(n, dtype=int)\n",
    "\n",
    "    if n_sub >= n:\n",
    "        return idx_all\n",
    "\n",
    "    idx_sub, _ = train_test_split(\n",
    "        idx_all,\n",
    "        train_size=n_sub,\n",
    "        stratify=y,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    return np.asarray(idx_sub, dtype=int)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main ablation (CIFAR-100, K=4)\n",
    "# =============================================================================\n",
    "\n",
    "def run_ablation(cfg: AblationConfig100) -> pd.DataFrame:\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "    rows = []\n",
    "\n",
    "    for sim in range(cfg.num_simulations):\n",
    "        print(f\"\\n=== Simulation {sim+1}/{cfg.num_simulations} ===\")\n",
    "        seed = cfg.train_seed_base + sim\n",
    "\n",
    "        # EXACT splits as your CIFAR-100 experiment\n",
    "        X_trP, X_tmp, y_trP, y_tmp = train_test_split(\n",
    "            X_train_full, Y_train_full,\n",
    "            test_size=1 - cfg.train_frac,\n",
    "            stratify=Y_train_full,\n",
    "            random_state=seed,\n",
    "        )\n",
    "        X_cal, X_rest, y_cal, y_rest = train_test_split(\n",
    "            X_tmp, y_tmp,\n",
    "            test_size=1 - cfg.cal_frac_of_temp,\n",
    "            stratify=y_tmp,\n",
    "            random_state=seed,\n",
    "        )\n",
    "        X_fuse_tr_full, X_fuse_cal, y_fuse_tr_full, y_fuse_cal = train_test_split(\n",
    "            X_rest, y_rest,\n",
    "            test_size=1 - cfg.fuse_train_frac_of_rest,\n",
    "            stratify=y_rest,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        X_te, y_te = X_test_full, Y_test_full\n",
    "        K = cfg.K_target\n",
    "        num_views = 4  # K=4 special-case matches your scripts\n",
    "\n",
    "        print(f\"\\n  -> K = {K} (ablation target)\")\n",
    "\n",
    "        # loaders per view\n",
    "        loaders = {}\n",
    "        for v in range(num_views):\n",
    "            tr_loader = torch.utils.data.DataLoader(\n",
    "                PatchesDataset(X_trP, y_trP, K, v),\n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=True,\n",
    "            )\n",
    "            cal_loader = torch.utils.data.DataLoader(\n",
    "                PatchesDataset(X_cal, y_cal, K, v),\n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=False,\n",
    "            )\n",
    "            ftr_loader = torch.utils.data.DataLoader(\n",
    "                PatchesDataset(X_fuse_tr_full, y_fuse_tr_full, K, v),\n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=False,\n",
    "            )\n",
    "            fcal_loader = torch.utils.data.DataLoader(\n",
    "                PatchesDataset(X_fuse_cal, y_fuse_cal, K, v),\n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=False,\n",
    "            )\n",
    "            te_loader = torch.utils.data.DataLoader(\n",
    "                PatchesDataset(X_te, y_te, K, v),\n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=False,\n",
    "            )\n",
    "            loaders[v] = dict(train=tr_loader, cal=cal_loader, ftr=ftr_loader, fcal=fcal_loader, te=te_loader)\n",
    "\n",
    "        # Train per-view predictors (match CIFAR-100 experiment)\n",
    "        models: List[PredictorCNN] = []\n",
    "        cal_classwise: List[Dict[int, np.ndarray]] = []\n",
    "        for v in range(num_views):\n",
    "            print(f\"    [View {v+1}/{num_views}] training...\")\n",
    "            m = PredictorCNN(num_classes=cfg.num_classes)\n",
    "            m = train_model(m, loaders[v][\"train\"], num_epochs=cfg.epochs_per_view, lr=cfg.lr)\n",
    "            models.append(m)\n",
    "\n",
    "            sc, lab = compute_nonconformity_scores(m, loaders[v][\"cal\"])\n",
    "            cal_classwise.append(classwise_scores(sc, lab, cfg.num_classes))\n",
    "\n",
    "        # Per-view p/probs for fusion train full, cal2, and test (match CIFAR-100 experiment)\n",
    "        pv_tr_full, pr_tr_full = [], []\n",
    "        pv_cal2,    pr_cal2    = [], []\n",
    "        pv_te,      pr_te      = [], []\n",
    "        for v in range(num_views):\n",
    "            p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"ftr\"], cfg.num_classes)\n",
    "            pv_tr_full.append(p); pr_tr_full.append(pr)\n",
    "\n",
    "            p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"fcal\"], cfg.num_classes)\n",
    "            pv_cal2.append(p); pr_cal2.append(pr)\n",
    "\n",
    "            p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"te\"], cfg.num_classes)\n",
    "            pv_te.append(p); pr_te.append(pr)\n",
    "\n",
    "        # Fixed test p-stack for baselines\n",
    "        P_test = np.stack(pv_te, axis=0)  # (K, n_test, L)\n",
    "\n",
    "        # Fixed features for cal2/test (cal2 remains full across nt_fracs)\n",
    "        X_cal2_feat = build_fusion_features(pv_cal2, pr_cal2)\n",
    "        X_test_feat = build_fusion_features(pv_te, pr_te)\n",
    "\n",
    "        n_t_full = len(y_fuse_tr_full)\n",
    "\n",
    "        for frac in cfg.nt_fracs:\n",
    "            n_sub = int(round(frac * n_t_full))\n",
    "            idx_sub = stratified_subsample_indices(\n",
    "                y_fuse_tr_full, n_sub, seed=seed + int(frac * 1000)\n",
    "            )\n",
    "\n",
    "            y_tr_sub = y_fuse_tr_full[idx_sub]\n",
    "            pv_tr_sub = [pv[idx_sub] for pv in pv_tr_full]\n",
    "            pr_tr_sub = [pr[idx_sub] for pr in pr_tr_full]\n",
    "\n",
    "            # -----------------------------\n",
    "            # CLF (Fusion LR on [p;prob]) trained on subset; conformalize on full cal2\n",
    "            # -----------------------------\n",
    "            X_ftr_sub = build_fusion_features(pv_tr_sub, pr_tr_sub)\n",
    "\n",
    "            fusion_lr = LogisticRegression(\n",
    "                max_iter=cfg.max_iter_lr,\n",
    "                multi_class=\"multinomial\",\n",
    "                solver=\"lbfgs\",\n",
    "                random_state=seed,\n",
    "            )\n",
    "            fusion_lr.fit(X_ftr_sub, y_tr_sub)\n",
    "\n",
    "            fused_probs_cal2 = fusion_lr.predict_proba(X_cal2_feat)\n",
    "            fused_cal_scores = fused_class_cal_scores(y_fuse_cal, fused_probs_cal2, cfg.num_classes)\n",
    "\n",
    "            fused_probs_test = fusion_lr.predict_proba(X_test_feat)\n",
    "            P_cf = fused_p_values_from_cal(fused_probs_test, fused_cal_scores)\n",
    "\n",
    "            cov_cf, size_cf = evaluate_sets(P_cf, y_te, cfg.alpha)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Adjusted Fisher baseline (depends on subset)\n",
    "            # -----------------------------\n",
    "            P_train_sub = np.stack(pv_tr_sub, axis=0)\n",
    "            P_adjF = adjusted_fisher_fusion(P_train_sub, y_tr_sub, P_test, cfg.num_classes)\n",
    "            cov_adjF, size_adjF = evaluate_sets(P_adjF, y_te, cfg.alpha)\n",
    "\n",
    "            rows.append(\n",
    "                dict(\n",
    "                    sim=sim,\n",
    "                    seed=seed,\n",
    "                    K=K,\n",
    "                    alpha=cfg.alpha,\n",
    "                    nt_frac=float(frac),\n",
    "                    nt_sub=int(len(idx_sub)),\n",
    "                    nt_full=int(n_t_full),\n",
    "                    cov_cf=float(cov_cf),\n",
    "                    size_cf=float(size_cf),\n",
    "                    cov_adjF=float(cov_adjF),\n",
    "                    size_adjF=float(size_adjF),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"    nt_frac={frac:.2f} (n={len(idx_sub):5d}) | \"\n",
    "                f\"CF: cov={cov_cf:.3f}, size={size_cf:.3f} | \"\n",
    "                f\"AdjF: cov={cov_adjF:.3f}, size={size_adjF:.3f}\"\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_csv = os.path.join(cfg.out_dir, \"cifar100_ablation_ntfrac_results.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nSaved raw results to: {out_csv}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_ablation(df: pd.DataFrame, cfg: AblationConfig100):\n",
    "    g = df.groupby(\"nt_frac\").agg(\n",
    "        cov_cf_mean=(\"cov_cf\", \"mean\"),\n",
    "        cov_cf_std=(\"cov_cf\", \"std\"),\n",
    "        size_cf_mean=(\"size_cf\", \"mean\"),\n",
    "        size_cf_std=(\"size_cf\", \"std\"),\n",
    "        cov_adjF_mean=(\"cov_adjF\", \"mean\"),\n",
    "        cov_adjF_std=(\"cov_adjF\", \"std\"),\n",
    "        size_adjF_mean=(\"size_adjF\", \"mean\"),\n",
    "        size_adjF_std=(\"size_adjF\", \"std\"),\n",
    "        nt_sub_mean=(\"nt_sub\", \"mean\"),\n",
    "    ).reset_index().sort_values(\"nt_frac\")\n",
    "\n",
    "    out_agg = os.path.join(cfg.out_dir, f\"cifar100_ablation_ntfrac_agg_K{cfg.K_target}.csv\")\n",
    "    g.to_csv(out_agg, index=False)\n",
    "    print(f\"Saved aggregated table to: {out_agg}\")\n",
    "\n",
    "    x = g[\"nt_frac\"].to_numpy()\n",
    "    xlab = r\"Fusion-train fraction $n_{\\mathrm{fuse}} / n_t$\"\n",
    "\n",
    "    # One-column figure: 2 stacked panels\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(3.35, 3.10), dpi=300, sharex=True)\n",
    "\n",
    "    # Coverage\n",
    "    ax = axes[0]\n",
    "    ax.plot(x, 100.0 * g[\"cov_cf_mean\"], label=\"CLF\")\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        100.0 * (g[\"cov_cf_mean\"] - g[\"cov_cf_std\"].fillna(0)),\n",
    "        100.0 * (g[\"cov_cf_mean\"] + g[\"cov_cf_std\"].fillna(0)),\n",
    "        alpha=0.2,\n",
    "        linewidth=0.0,\n",
    "    )\n",
    "    ax.plot(x, 100.0 * g[\"cov_adjF_mean\"], label=\"Adjusted Fisher\", linestyle=\"--\")\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        100.0 * (g[\"cov_adjF_mean\"] - g[\"cov_adjF_std\"].fillna(0)),\n",
    "        100.0 * (g[\"cov_adjF_mean\"] + g[\"cov_adjF_std\"].fillna(0)),\n",
    "        alpha=0.2,\n",
    "        linewidth=0.0,\n",
    "    )\n",
    "    ax.axhline(100.0 * (1.0 - cfg.alpha), linestyle=\":\", linewidth=0.8, label=r\"Target $1-\\alpha$\")\n",
    "    ax.set_ylabel(\"Coverage (%)\")\n",
    "    ax.set_title(r\"CIFAR-100 (K=4): Coverage vs $n_{\\mathrm{fuse}}/n_t$\")\n",
    "    ax.set_ylim(100.0 * (1.0 - cfg.alpha) - 5.0, 100.0 * (1.0 - cfg.alpha) + 5.0)\n",
    "    ax.legend(frameon=False, ncol=2)\n",
    "\n",
    "    # Set size\n",
    "    ax = axes[1]\n",
    "    ax.plot(x, g[\"size_cf_mean\"], label=\"CLF\")\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        (g[\"size_cf_mean\"] - g[\"size_cf_std\"].fillna(0)),\n",
    "        (g[\"size_cf_mean\"] + g[\"size_cf_std\"].fillna(0)),\n",
    "        alpha=0.2,\n",
    "        linewidth=0.0,\n",
    "    )\n",
    "    ax.plot(x, g[\"size_adjF_mean\"], label=\"Adjusted Fisher\", linestyle=\"--\")\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        (g[\"size_adjF_mean\"] - g[\"size_adjF_std\"].fillna(0)),\n",
    "        (g[\"size_adjF_mean\"] + g[\"size_adjF_std\"].fillna(0)),\n",
    "        alpha=0.2,\n",
    "        linewidth=0.0,\n",
    "    )\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(\"Avg. set size\")\n",
    "    ax.set_title(r\"CIFAR-100 (K=4): Set size vs $n_{\\mathrm{fuse}}/n_t$\")\n",
    "    ax.legend(frameon=False, ncol=2)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "        tick.set_ha(\"right\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_pdf = os.path.join(cfg.out_dir, f\"cifar100_ablation_ntfrac_cifar100_K{cfg.K_target}.pdf\")\n",
    "    out_png = os.path.join(cfg.out_dir, f\"cifar100_ablation_ntfrac_cifar100_K{cfg.K_target}.png\")\n",
    "    fig.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    print(f\"Saved figure to:\\n  {out_pdf}\\n  {out_png}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = AblationConfig100()\n",
    "    df = run_ablation(cfg)\n",
    "    plot_ablation(df, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e41cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
