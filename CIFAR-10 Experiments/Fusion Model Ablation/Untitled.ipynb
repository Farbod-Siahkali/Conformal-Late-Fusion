{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03c622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "=== Sim 1/10 (seed=42) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 2/10 (seed=43) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 3/10 (seed=44) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 4/10 (seed=45) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 5/10 (seed=46) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 6/10 (seed=47) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 7/10 (seed=48) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 8/10 (seed=49) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 9/10 (seed=50) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 10/10 (seed=51) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Per-simulation raw results ===\n",
      "   sim  LR_full_cov(%)  LR_full_set  MLP_full_cov(%)  MLP_full_set  \\\n",
      "0    0           90.61       3.4642            90.84        3.3841   \n",
      "1    1           90.66       3.4730            90.43        3.3603   \n",
      "2    2           89.66       3.3015            89.85        3.2489   \n",
      "3    3           90.83       3.4299            91.12        3.3511   \n",
      "4    4           90.34       3.3478            90.83        3.3453   \n",
      "5    5           90.16       3.3959            90.00        3.3084   \n",
      "6    6           90.48       3.4633            90.64        3.3980   \n",
      "7    7           90.29       3.4124            89.80        3.2540   \n",
      "8    8           89.82       3.3351            89.94        3.3337   \n",
      "9    9           90.29       3.3756            90.24        3.3397   \n",
      "\n",
      "   LR_p_cov(%)  LR_p_set  \n",
      "0        90.54    3.4609  \n",
      "1        90.78    3.4825  \n",
      "2        89.66    3.2983  \n",
      "3        90.89    3.4422  \n",
      "4        90.37    3.3608  \n",
      "5        90.13    3.3970  \n",
      "6        90.53    3.4897  \n",
      "7        90.11    3.3926  \n",
      "8        90.07    3.3842  \n",
      "9        90.19    3.3786  \n",
      "\n",
      "=== Summary over simulations (mean (std)) ===\n",
      "                         Method  Coverage (%) Avg set size\n",
      "0           Fusion LR [$\\Pi;p$]  90.31 (0.36)  3.40 (0.06)\n",
      "1  Fusion 2-layer MLP [$\\Pi;p$]  90.37 (0.47)  3.33 (0.05)\n",
      "2          Fusion LR [$p$ only]  90.33 (0.37)  3.41 (0.06)\n",
      "\n",
      "Saved: fusion_arch_input_ablation_k4_summary.csv, fusion_arch_input_ablation_k4_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 (K=4) fusion-architecture + input-feature ablation:\n",
    "# Compare Stage-2 fusion model:\n",
    "#   (A) Multinomial LR on [p; prob]          (your default)\n",
    "#   (B) 2-hidden-layer MLP on [p; prob]\n",
    "#   (C) Multinomial LR on p-only\n",
    "# Everything else matches: per-view CNNs, splits, seeds, epochs, lr, batch size, sims, alpha.\n",
    "#\n",
    "# Paste-and-run. Produces a small summary table (mean (std)) over simulations.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# Config (match your existing params)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    alpha: float = 0.1\n",
    "    K: int = 4\n",
    "    L: int = 10\n",
    "    num_simulations: int = 10\n",
    "\n",
    "    # per-view CNN training\n",
    "    epochs_per_view: int = 100\n",
    "    lr: float = 1e-3\n",
    "    batch_size: int = 512\n",
    "\n",
    "    # fusion models\n",
    "    max_iter_lr: int = 1000          # sklearn LR iterations\n",
    "    fusion_epochs: int = 100         # MLP fusion epochs (explicit)\n",
    "    fusion_hidden1: int = 128\n",
    "    fusion_hidden2: int = 128\n",
    "    fusion_weight_decay: float = 1e-4\n",
    "\n",
    "    # splits (same structure as your script)\n",
    "    train_frac: float = 0.5\n",
    "    cal_frac_of_temp: float = 0.3\n",
    "    fuse_train_frac_of_rest: float = 0.7\n",
    "\n",
    "    seed_base: int = 42\n",
    "\n",
    "cfg = Cfg()\n",
    "\n",
    "# =============================================================================\n",
    "# Device / determinism\n",
    "# =============================================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_all_seeds(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# =============================================================================\n",
    "# Data\n",
    "# =============================================================================\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "X_train_full = train_dataset.data.astype(np.float32) / 255.0\n",
    "Y_train_full = np.array(train_dataset.targets, dtype=int)\n",
    "X_test_full  = test_dataset.data.astype(np.float32) / 255.0\n",
    "Y_test_full  = np.array(test_dataset.targets, dtype=int)\n",
    "\n",
    "# =============================================================================\n",
    "# Multi-view patching (same as your code)\n",
    "# =============================================================================\n",
    "\n",
    "def split_image_into_k_patches(image: torch.Tensor, k: int) -> List[torch.Tensor]:\n",
    "    # image: (3,32,32)\n",
    "    C, H, W = image.shape\n",
    "    if k == 4:\n",
    "        patches = []\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                patches.append(image[:, i*16:(i+1)*16, j*16:(j+1)*16])\n",
    "        return patches\n",
    "    else:\n",
    "        base_width = W // k\n",
    "        remainder = W % k\n",
    "        patches, start = [], 0\n",
    "        for idx in range(k):\n",
    "            width = base_width + (1 if idx < remainder else 0)\n",
    "            patches.append(image[:, :, start:start+width])\n",
    "            start += width\n",
    "        return patches\n",
    "\n",
    "class PatchesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images: np.ndarray, labels: np.ndarray, k: int, view: int):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.k = k\n",
    "        self.view = view\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img = self.images[idx].transpose((2, 0, 1))  # (3,32,32)\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        patches = split_image_into_k_patches(img, self.k)\n",
    "        x = patches[self.view]\n",
    "        y = int(self.labels[idx])\n",
    "        return x, y\n",
    "\n",
    "# =============================================================================\n",
    "# Per-view CNN (same as your code)\n",
    "# =============================================================================\n",
    "\n",
    "class PredictorCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1   = None\n",
    "        self.fc2   = None\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        if self.fc1 is None:\n",
    "            b, c, h, w = x.shape\n",
    "            self.fc1 = nn.Linear(c*h*w, 128).to(x.device)\n",
    "            self.fc2 = nn.Linear(128, self.num_classes).to(x.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def train_view_model(model: nn.Module, train_loader, num_epochs: int, lr: float):\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    opt  = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    for ep in range(num_epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = torch.tensor(yb, dtype=torch.long, device=device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if (ep + 1) % 25 == 0:\n",
    "            print(f\"      view-epoch {ep+1}/{num_epochs}\")\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# Conformal utilities\n",
    "# =============================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_true_label_scores(model: nn.Module, loader) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    scores, labels = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = F.softmax(model(xb), dim=1)\n",
    "        idx = torch.arange(probs.size(0), device=probs.device)\n",
    "        true_p = probs[idx, torch.tensor(yb, dtype=torch.long, device=probs.device)]\n",
    "        s = (1.0 - true_p).detach().cpu().numpy()\n",
    "        scores.append(s)\n",
    "        labels.append(yb.numpy())\n",
    "    return np.concatenate(scores, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "def classwise_scores(scores: np.ndarray, labels: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for s, y in zip(scores, labels):\n",
    "        out[int(y)].append(float(s))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "@torch.no_grad()\n",
    "def per_view_pvalues_and_probs(model: nn.Module, cal_scores: Dict[int, np.ndarray], loader, L: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    probs_all = []\n",
    "    for xb, _ in loader:\n",
    "        xb = xb.to(device)\n",
    "        probs_all.append(F.softmax(model(xb), dim=1).detach().cpu().numpy())\n",
    "    probs_all = np.vstack(probs_all)  # (n, L)\n",
    "\n",
    "    n = probs_all.shape[0]\n",
    "    pvals = np.zeros((n, L), dtype=float)\n",
    "    for y in range(L):\n",
    "        cal = cal_scores.get(y, np.array([], dtype=float))\n",
    "        if cal.size == 0:\n",
    "            pvals[:, y] = 1.0\n",
    "        else:\n",
    "            s_test = 1.0 - probs_all[:, y]\n",
    "            counts = np.sum(cal[:, None] >= s_test[None, :], axis=0)\n",
    "            pvals[:, y] = (1.0 + counts) / (len(cal) + 1.0)\n",
    "    return pvals, probs_all\n",
    "\n",
    "def build_fusion_features_full(pvals_list: List[np.ndarray], probs_list: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"[p; prob] blocks per view => (n, K*2L)\"\"\"\n",
    "    blocks = [np.hstack([pvals_list[k], probs_list[k]]) for k in range(len(pvals_list))]\n",
    "    return np.hstack(blocks)\n",
    "\n",
    "def build_fusion_features_p_only(pvals_list: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"p-only blocks per view => (n, K*L)\"\"\"\n",
    "    return np.hstack(pvals_list)\n",
    "\n",
    "def fused_class_cal_scores(y_cal: np.ndarray, fused_probs_cal: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    s = 1.0 - fused_probs_cal[np.arange(len(y_cal)), y_cal]\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for sc, yy in zip(s, y_cal):\n",
    "        out[int(yy)].append(float(sc))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "def fused_p_values_from_cal(fused_probs: np.ndarray, cal_class_scores: Dict[int, np.ndarray]) -> np.ndarray:\n",
    "    n, L = fused_probs.shape\n",
    "    out = np.zeros((n, L), dtype=float)\n",
    "    for y in range(L):\n",
    "        cal = cal_class_scores.get(y, np.array([], dtype=float))\n",
    "        if cal.size == 0:\n",
    "            out[:, y] = 1.0\n",
    "        else:\n",
    "            s_test = 1.0 - fused_probs[:, y]\n",
    "            counts = np.sum(cal[:, None] >= s_test[None, :], axis=0)\n",
    "            out[:, y] = (1.0 + counts) / (len(cal) + 1.0)\n",
    "    return out\n",
    "\n",
    "def eval_sets_from_pvals(P: np.ndarray, y_true: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    C = (P > alpha)\n",
    "    cov = float(np.mean(C[np.arange(len(y_true)), y_true]))\n",
    "    size = float(np.mean(C.sum(axis=1)))\n",
    "    return cov, size\n",
    "\n",
    "# =============================================================================\n",
    "# Fusion MLP (2 hidden layers) for [p; prob]\n",
    "# =============================================================================\n",
    "\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, d_in: int, d_h1: int, d_h2: int, d_out: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_in, d_h1)\n",
    "        self.fc2 = nn.Linear(d_h1, d_h2)\n",
    "        self.fc3 = nn.Linear(d_h2, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def train_fusion_mlp(X: np.ndarray, y: np.ndarray, d_in: int, L: int, seed: int) -> FusionMLP:\n",
    "    set_all_seeds(seed)\n",
    "    model = FusionMLP(d_in, cfg.fusion_hidden1, cfg.fusion_hidden2, L).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.fusion_weight_decay)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    X_t = torch.tensor(X, dtype=torch.float32)\n",
    "    y_t = torch.tensor(y, dtype=torch.long)\n",
    "    ds = torch.utils.data.TensorDataset(X_t, y_t)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(cfg.fusion_epochs):\n",
    "        for xb, yb in dl:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def fusion_mlp_predict_proba(model: FusionMLP, X: np.ndarray) -> np.ndarray:\n",
    "    model.eval()\n",
    "    X_t = torch.tensor(X, dtype=torch.float32)\n",
    "    dl = torch.utils.data.DataLoader(X_t, batch_size=4096, shuffle=False)\n",
    "    probs = []\n",
    "    for xb in dl:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs.append(F.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "    return np.vstack(probs)\n",
    "\n",
    "# =============================================================================\n",
    "# One simulation for K=4, returning metrics for:\n",
    "#   LR([p;prob]) vs MLP([p;prob]) vs LR(p-only)\n",
    "# =============================================================================\n",
    "\n",
    "def run_one_sim(sim: int) -> Dict[str, float]:\n",
    "    seed = cfg.seed_base + sim\n",
    "    set_all_seeds(seed)\n",
    "\n",
    "    # Splits (match your script)\n",
    "    X_trP, X_tmp, y_trP, y_tmp = train_test_split(\n",
    "        X_train_full, Y_train_full,\n",
    "        test_size=1 - cfg.train_frac,\n",
    "        stratify=Y_train_full,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    X_cal, X_rest, y_cal, y_rest = train_test_split(\n",
    "        X_tmp, y_tmp,\n",
    "        test_size=1 - cfg.cal_frac_of_temp,\n",
    "        stratify=y_tmp,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    X_fuse_tr, X_fuse_cal, y_fuse_tr, y_fuse_cal = train_test_split(\n",
    "        X_rest, y_rest,\n",
    "        test_size=1 - cfg.fuse_train_frac_of_rest,\n",
    "        stratify=y_rest,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    num_views = 4\n",
    "    loaders = {}\n",
    "    for v in range(num_views):\n",
    "        tr_loader   = torch.utils.data.DataLoader(PatchesDataset(X_trP,       y_trP,       cfg.K, v), batch_size=cfg.batch_size, shuffle=True)\n",
    "        cal_loader  = torch.utils.data.DataLoader(PatchesDataset(X_cal,       y_cal,       cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        ftr_loader  = torch.utils.data.DataLoader(PatchesDataset(X_fuse_tr,   y_fuse_tr,   cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        fcal_loader = torch.utils.data.DataLoader(PatchesDataset(X_fuse_cal,  y_fuse_cal,  cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        te_loader   = torch.utils.data.DataLoader(PatchesDataset(X_test_full, Y_test_full, cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        loaders[v] = dict(train=tr_loader, cal=cal_loader, ftr=ftr_loader, fcal=fcal_loader, te=te_loader)\n",
    "\n",
    "    # Train per-view CNNs + cal1 classwise score sets\n",
    "    models, cal_classwise = [], []\n",
    "    print(f\"\\n=== Sim {sim+1}/{cfg.num_simulations} (seed={seed}) ===\")\n",
    "    for v in range(num_views):\n",
    "        print(f\"  [View {v+1}/{num_views}] training...\")\n",
    "        m = PredictorCNN(num_classes=cfg.L)\n",
    "        m = train_view_model(m, loaders[v][\"train\"], num_epochs=cfg.epochs_per_view, lr=cfg.lr)\n",
    "        models.append(m)\n",
    "        sc, lab = compute_true_label_scores(m, loaders[v][\"cal\"])\n",
    "        cal_classwise.append(classwise_scores(sc, lab, cfg.L))\n",
    "\n",
    "    # Per-view p/probs for fusion-train, fusion-cal2, test\n",
    "    pv_tr, pr_tr = [], []\n",
    "    pv_cal2, pr_cal2 = [], []\n",
    "    pv_te, pr_te = [], []\n",
    "    for v in range(num_views):\n",
    "        p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"ftr\"], cfg.L)\n",
    "        pv_tr.append(p); pr_tr.append(pr)\n",
    "        p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"fcal\"], cfg.L)\n",
    "        pv_cal2.append(p); pr_cal2.append(pr)\n",
    "        p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"te\"], cfg.L)\n",
    "        pv_te.append(p); pr_te.append(pr)\n",
    "\n",
    "    # Features\n",
    "    X_ftr_full   = build_fusion_features_full(pv_tr, pr_tr)\n",
    "    X_fcal2_full = build_fusion_features_full(pv_cal2, pr_cal2)\n",
    "    X_ftest_full = build_fusion_features_full(pv_te, pr_te)\n",
    "\n",
    "    X_ftr_ponly   = build_fusion_features_p_only(pv_tr)\n",
    "    X_fcal2_ponly = build_fusion_features_p_only(pv_cal2)\n",
    "    X_ftest_ponly = build_fusion_features_p_only(pv_te)\n",
    "\n",
    "    # =========================================================\n",
    "    # (A) Fusion = multinomial LR on [p;prob], then conformalize\n",
    "    # =========================================================\n",
    "    fusion_lr_full = LogisticRegression(\n",
    "        max_iter=cfg.max_iter_lr,\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    fusion_lr_full.fit(X_ftr_full, y_fuse_tr)\n",
    "\n",
    "    fused_probs_cal_lr_full  = fusion_lr_full.predict_proba(X_fcal2_full)\n",
    "    fused_cal_scores_lr_full = fused_class_cal_scores(y_fuse_cal, fused_probs_cal_lr_full, cfg.L)\n",
    "    fused_probs_test_lr_full = fusion_lr_full.predict_proba(X_ftest_full)\n",
    "    P_lr_full                = fused_p_values_from_cal(fused_probs_test_lr_full, fused_cal_scores_lr_full)\n",
    "\n",
    "    cov_lr_full, set_lr_full = eval_sets_from_pvals(P_lr_full, Y_test_full, cfg.alpha)\n",
    "\n",
    "    # =========================================================\n",
    "    # (B) Fusion = 2-hidden-layer MLP on [p;prob], conformalize\n",
    "    # =========================================================\n",
    "    fusion_mlp = train_fusion_mlp(X_ftr_full, y_fuse_tr, d_in=X_ftr_full.shape[1], L=cfg.L, seed=seed)\n",
    "    fused_probs_cal_mlp  = fusion_mlp_predict_proba(fusion_mlp, X_fcal2_full)\n",
    "    fused_cal_scores_mlp = fused_class_cal_scores(y_fuse_cal, fused_probs_cal_mlp, cfg.L)\n",
    "    fused_probs_test_mlp = fusion_mlp_predict_proba(fusion_mlp, X_ftest_full)\n",
    "    P_mlp_full           = fused_p_values_from_cal(fused_probs_test_mlp, fused_cal_scores_mlp)\n",
    "\n",
    "    cov_mlp_full, set_mlp_full = eval_sets_from_pvals(P_mlp_full, Y_test_full, cfg.alpha)\n",
    "\n",
    "    # =========================================================\n",
    "    # (C) Fusion = multinomial LR on p-only, then conformalize\n",
    "    # =========================================================\n",
    "    fusion_lr_p = LogisticRegression(\n",
    "        max_iter=cfg.max_iter_lr,\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    fusion_lr_p.fit(X_ftr_ponly, y_fuse_tr)\n",
    "\n",
    "    fused_probs_cal_lr_p  = fusion_lr_p.predict_proba(X_fcal2_ponly)\n",
    "    fused_cal_scores_lr_p = fused_class_cal_scores(y_fuse_cal, fused_probs_cal_lr_p, cfg.L)\n",
    "    fused_probs_test_lr_p = fusion_lr_p.predict_proba(X_ftest_ponly)\n",
    "    P_lr_p                = fused_p_values_from_cal(fused_probs_test_lr_p, fused_cal_scores_lr_p)\n",
    "\n",
    "    cov_lr_p, set_lr_p = eval_sets_from_pvals(P_lr_p, Y_test_full, cfg.alpha)\n",
    "\n",
    "    return {\n",
    "        \"sim\": sim,\n",
    "        \"LR_full_cov(%)\": 100.0 * cov_lr_full,\n",
    "        \"LR_full_set\": set_lr_full,\n",
    "        \"MLP_full_cov(%)\": 100.0 * cov_mlp_full,\n",
    "        \"MLP_full_set\": set_mlp_full,\n",
    "        \"LR_p_cov(%)\": 100.0 * cov_lr_p,\n",
    "        \"LR_p_set\": set_lr_p,\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Run all sims + print summary table\n",
    "# =============================================================================\n",
    "\n",
    "rows = []\n",
    "for sim in range(cfg.num_simulations):\n",
    "    rows.append(run_one_sim(sim))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "def mean_std_str(x: pd.Series) -> str:\n",
    "    return f\"{x.mean():.2f} ({x.std(ddof=1):.2f})\"\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"Method\": [\n",
    "        r\"Fusion LR [$\\Pi;p$]\",\n",
    "        r\"Fusion 2-layer MLP [$\\Pi;p$]\",\n",
    "        r\"Fusion LR [$p$ only]\",\n",
    "    ],\n",
    "    \"Coverage (%)\": [\n",
    "        mean_std_str(df[\"LR_full_cov(%)\"]),\n",
    "        mean_std_str(df[\"MLP_full_cov(%)\"]),\n",
    "        mean_std_str(df[\"LR_p_cov(%)\"]),\n",
    "    ],\n",
    "    \"Avg set size\": [\n",
    "        mean_std_str(df[\"LR_full_set\"]),\n",
    "        mean_std_str(df[\"MLP_full_set\"]),\n",
    "        mean_std_str(df[\"LR_p_set\"]),\n",
    "    ],\n",
    "})\n",
    "\n",
    "print(\"\\n=== Per-simulation raw results ===\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\n=== Summary over simulations (mean (std)) ===\")\n",
    "print(summary)\n",
    "\n",
    "# Optional: save\n",
    "summary.to_csv(\"fusion_arch_input_ablation_k4_summary.csv\", index=False)\n",
    "df.to_csv(\"fusion_arch_input_ablation_k4_raw.csv\", index=False)\n",
    "print(\"\\nSaved: fusion_arch_input_ablation_k4_summary.csv, fusion_arch_input_ablation_k4_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae919ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "=== Sim 1/10 (seed=42) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 2/10 (seed=43) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 3/10 (seed=44) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 4/10 (seed=45) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 5/10 (seed=46) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 6/10 (seed=47) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 7/10 (seed=48) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 8/10 (seed=49) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 9/10 (seed=50) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Sim 10/10 (seed=51) ===\n",
      "  [View 1/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 2/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 3/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "  [View 4/4] training...\n",
      "      view-epoch 25/100\n",
      "      view-epoch 50/100\n",
      "      view-epoch 75/100\n",
      "      view-epoch 100/100\n",
      "\n",
      "=== Per-simulation raw results ===\n",
      "   sim  LR_cov(%)  LR_set  MLP_cov(%)  MLP_set\n",
      "0    0      91.12  3.4856       90.91   3.3663\n",
      "1    1      91.07  3.5149       90.77   3.4186\n",
      "2    2      89.27  3.2810       89.85   3.2646\n",
      "3    3      90.92  3.4635       90.68   3.3627\n",
      "4    4      90.69  3.4021       90.33   3.3089\n",
      "5    5      90.28  3.3648       90.13   3.2995\n",
      "6    6      90.69  3.4731       91.26   3.4722\n",
      "7    7      90.59  3.4339       90.31   3.2623\n",
      "8    8      90.06  3.3985       89.88   3.3542\n",
      "9    9      90.41  3.3717       90.51   3.3109\n",
      "\n",
      "=== Summary over simulations (mean (std)) ===\n",
      "               Method  Coverage (%) Avg set size\n",
      "0           Fusion LR  90.51 (0.55)  3.42 (0.07)\n",
      "1  Fusion 2-layer MLP  90.46 (0.45)  3.34 (0.07)\n",
      "\n",
      "Saved: fusion_arch_ablation_k4_summary.csv, fusion_arch_ablation_k4_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 (K=4) fusion-architecture ablation:\n",
    "# Compare Stage-2 fusion model = (A) multinomial LR vs (B) 2-hidden-layer MLP\n",
    "# Everything else matches: per-view CNNs, splits, seeds, epochs, lr, batch size, sims, alpha.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# Config (match your existing params)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    alpha: float = 0.1\n",
    "    K: int = 4\n",
    "    L: int = 10\n",
    "    num_simulations: int = 10\n",
    "\n",
    "    # per-view CNN training\n",
    "    epochs_per_view: int = 100\n",
    "    lr: float = 1e-3\n",
    "    batch_size: int = 512\n",
    "\n",
    "    # fusion models\n",
    "    max_iter_lr: int = 1000          # sklearn LR iterations\n",
    "    fusion_epochs: int = 100         # MLP fusion epochs (explicit)\n",
    "    fusion_hidden1: int = 128\n",
    "    fusion_hidden2: int = 128\n",
    "    fusion_weight_decay: float = 1e-4\n",
    "\n",
    "    # splits (same structure as your script)\n",
    "    train_frac: float = 0.5\n",
    "    cal_frac_of_temp: float = 0.3\n",
    "    fuse_train_frac_of_rest: float = 0.7\n",
    "\n",
    "    seed_base: int = 42\n",
    "\n",
    "cfg = Cfg()\n",
    "\n",
    "# =============================================================================\n",
    "# Device / determinism\n",
    "# =============================================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_all_seeds(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # Reasonable reproducibility without forcing full determinism slowdowns:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# =============================================================================\n",
    "# Data\n",
    "# =============================================================================\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "X_train_full = train_dataset.data.astype(np.float32) / 255.0\n",
    "Y_train_full = np.array(train_dataset.targets, dtype=int)\n",
    "X_test_full  = test_dataset.data.astype(np.float32) / 255.0\n",
    "Y_test_full  = np.array(test_dataset.targets, dtype=int)\n",
    "\n",
    "# =============================================================================\n",
    "# Multi-view patching (same as your code)\n",
    "# =============================================================================\n",
    "\n",
    "def split_image_into_k_patches(image: torch.Tensor, k: int) -> List[torch.Tensor]:\n",
    "    # image: (3,32,32)\n",
    "    C, H, W = image.shape\n",
    "    if k == 4:\n",
    "        patches = []\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                patches.append(image[:, i*16:(i+1)*16, j*16:(j+1)*16])\n",
    "        return patches\n",
    "    else:\n",
    "        base_width = W // k\n",
    "        remainder = W % k\n",
    "        patches, start = [], 0\n",
    "        for idx in range(k):\n",
    "            width = base_width + (1 if idx < remainder else 0)\n",
    "            patches.append(image[:, :, start:start+width])\n",
    "            start += width\n",
    "        return patches\n",
    "\n",
    "class PatchesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images: np.ndarray, labels: np.ndarray, k: int, view: int):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.k = k\n",
    "        self.view = view\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img = self.images[idx].transpose((2, 0, 1))  # (3,32,32)\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        patches = split_image_into_k_patches(img, self.k)\n",
    "        x = patches[self.view]\n",
    "        y = int(self.labels[idx])\n",
    "        return x, y\n",
    "\n",
    "# =============================================================================\n",
    "# Per-view CNN (same as your code)\n",
    "# =============================================================================\n",
    "\n",
    "class PredictorCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1   = None\n",
    "        self.fc2   = None\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        if self.fc1 is None:\n",
    "            b, c, h, w = x.shape\n",
    "            self.fc1 = nn.Linear(c*h*w, 128).to(x.device)\n",
    "            self.fc2 = nn.Linear(128, self.num_classes).to(x.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def train_view_model(model: nn.Module, train_loader, num_epochs: int, lr: float):\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    opt  = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    for ep in range(num_epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = torch.tensor(yb, dtype=torch.long, device=device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if (ep + 1) % 25 == 0:\n",
    "            print(f\"      view-epoch {ep+1}/{num_epochs}\")\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# Conformal utilities (same logic as your code)\n",
    "# =============================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_true_label_scores(model: nn.Module, loader) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    scores, labels = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = F.softmax(model(xb), dim=1)\n",
    "        idx = torch.arange(probs.size(0), device=probs.device)\n",
    "        true_p = probs[idx, torch.tensor(yb, dtype=torch.long, device=probs.device)]\n",
    "        s = (1.0 - true_p).detach().cpu().numpy()\n",
    "        scores.append(s)\n",
    "        labels.append(yb.numpy())\n",
    "    return np.concatenate(scores, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "def classwise_scores(scores: np.ndarray, labels: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for s, y in zip(scores, labels):\n",
    "        out[int(y)].append(float(s))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "@torch.no_grad()\n",
    "def per_view_pvalues_and_probs(model: nn.Module, cal_scores: Dict[int, np.ndarray], loader, L: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    probs_all = []\n",
    "    for xb, _ in loader:\n",
    "        xb = xb.to(device)\n",
    "        probs_all.append(F.softmax(model(xb), dim=1).detach().cpu().numpy())\n",
    "    probs_all = np.vstack(probs_all)  # (n, L)\n",
    "\n",
    "    n = probs_all.shape[0]\n",
    "    pvals = np.zeros((n, L), dtype=float)\n",
    "    for y in range(L):\n",
    "        cal = cal_scores.get(y, np.array([], dtype=float))\n",
    "        if cal.size == 0:\n",
    "            pvals[:, y] = 1.0\n",
    "        else:\n",
    "            s_test = 1.0 - probs_all[:, y]\n",
    "            counts = np.sum(cal[:, None] >= s_test[None, :], axis=0)\n",
    "            pvals[:, y] = (1.0 + counts) / (len(cal) + 1.0)\n",
    "    return pvals, probs_all\n",
    "\n",
    "def build_fusion_features(pvals_list: List[np.ndarray], probs_list: List[np.ndarray]) -> np.ndarray:\n",
    "    blocks = [np.hstack([pvals_list[k], probs_list[k]]) for k in range(len(pvals_list))]\n",
    "    return np.hstack(blocks)\n",
    "\n",
    "def fused_class_cal_scores(y_cal: np.ndarray, fused_probs_cal: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    s = 1.0 - fused_probs_cal[np.arange(len(y_cal)), y_cal]\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for sc, yy in zip(s, y_cal):\n",
    "        out[int(yy)].append(float(sc))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "def fused_p_values_from_cal(fused_probs: np.ndarray, cal_class_scores: Dict[int, np.ndarray]) -> np.ndarray:\n",
    "    n, L = fused_probs.shape\n",
    "    out = np.zeros((n, L), dtype=float)\n",
    "    for y in range(L):\n",
    "        cal = cal_class_scores.get(y, np.array([], dtype=float))\n",
    "        if cal.size == 0:\n",
    "            out[:, y] = 1.0\n",
    "        else:\n",
    "            s_test = 1.0 - fused_probs[:, y]\n",
    "            counts = np.sum(cal[:, None] >= s_test[None, :], axis=0)\n",
    "            out[:, y] = (1.0 + counts) / (len(cal) + 1.0)\n",
    "    return out\n",
    "\n",
    "def eval_sets_from_pvals(P: np.ndarray, y_true: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    C = (P > alpha)\n",
    "    cov = float(np.mean(C[np.arange(len(y_true)), y_true]))\n",
    "    size = float(np.mean(C.sum(axis=1)))\n",
    "    return cov, size\n",
    "\n",
    "# =============================================================================\n",
    "# Fusion MLP (2 hidden layers)\n",
    "# =============================================================================\n",
    "\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, d_in: int, d_h1: int, d_h2: int, d_out: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_in, d_h1)\n",
    "        self.fc2 = nn.Linear(d_h1, d_h2)\n",
    "        self.fc3 = nn.Linear(d_h2, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def train_fusion_mlp(X: np.ndarray, y: np.ndarray, d_in: int, L: int, seed: int) -> FusionMLP:\n",
    "    set_all_seeds(seed)\n",
    "    model = FusionMLP(d_in, cfg.fusion_hidden1, cfg.fusion_hidden2, L).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.fusion_weight_decay)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    # torch dataset\n",
    "    X_t = torch.tensor(X, dtype=torch.float32)\n",
    "    y_t = torch.tensor(y, dtype=torch.long)\n",
    "    ds = torch.utils.data.TensorDataset(X_t, y_t)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(cfg.fusion_epochs):\n",
    "        for xb, yb in dl:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def fusion_mlp_predict_proba(model: FusionMLP, X: np.ndarray) -> np.ndarray:\n",
    "    model.eval()\n",
    "    X_t = torch.tensor(X, dtype=torch.float32)\n",
    "    dl = torch.utils.data.DataLoader(X_t, batch_size=4096, shuffle=False)\n",
    "    probs = []\n",
    "    for xb in dl:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs.append(F.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "    return np.vstack(probs)\n",
    "\n",
    "# =============================================================================\n",
    "# One simulation for K=4, returning metrics for LR vs MLP\n",
    "# =============================================================================\n",
    "\n",
    "def run_one_sim(sim: int) -> Dict[str, float]:\n",
    "    seed = cfg.seed_base + sim\n",
    "    set_all_seeds(seed)\n",
    "\n",
    "    # Splits (match your script)\n",
    "    X_trP, X_tmp, y_trP, y_tmp = train_test_split(\n",
    "        X_train_full, Y_train_full,\n",
    "        test_size=1 - cfg.train_frac,\n",
    "        stratify=Y_train_full,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    X_cal, X_rest, y_cal, y_rest = train_test_split(\n",
    "        X_tmp, y_tmp,\n",
    "        test_size=1 - cfg.cal_frac_of_temp,\n",
    "        stratify=y_tmp,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    X_fuse_tr, X_fuse_cal, y_fuse_tr, y_fuse_cal = train_test_split(\n",
    "        X_rest, y_rest,\n",
    "        test_size=1 - cfg.fuse_train_frac_of_rest,\n",
    "        stratify=y_rest,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    # K=4 -> 4 views\n",
    "    num_views = 4\n",
    "    loaders = {}\n",
    "    for v in range(num_views):\n",
    "        tr_loader   = torch.utils.data.DataLoader(PatchesDataset(X_trP,      y_trP,      cfg.K, v), batch_size=cfg.batch_size, shuffle=True)\n",
    "        cal_loader  = torch.utils.data.DataLoader(PatchesDataset(X_cal,      y_cal,      cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        ftr_loader  = torch.utils.data.DataLoader(PatchesDataset(X_fuse_tr,  y_fuse_tr,  cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        fcal_loader = torch.utils.data.DataLoader(PatchesDataset(X_fuse_cal, y_fuse_cal, cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        te_loader   = torch.utils.data.DataLoader(PatchesDataset(X_test_full, Y_test_full, cfg.K, v), batch_size=cfg.batch_size, shuffle=False)\n",
    "        loaders[v] = dict(train=tr_loader, cal=cal_loader, ftr=ftr_loader, fcal=fcal_loader, te=te_loader)\n",
    "\n",
    "    # Train per-view CNNs + cal1 classwise score sets\n",
    "    models, cal_classwise = [], []\n",
    "    print(f\"\\n=== Sim {sim+1}/{cfg.num_simulations} (seed={seed}) ===\")\n",
    "    for v in range(num_views):\n",
    "        print(f\"  [View {v+1}/{num_views}] training...\")\n",
    "        m = PredictorCNN(num_classes=cfg.L)\n",
    "        m = train_view_model(m, loaders[v][\"train\"], num_epochs=cfg.epochs_per_view, lr=cfg.lr)\n",
    "        models.append(m)\n",
    "        sc, lab = compute_true_label_scores(m, loaders[v][\"cal\"])\n",
    "        cal_classwise.append(classwise_scores(sc, lab, cfg.L))\n",
    "\n",
    "    # Per-view p/probs for fusion-train, fusion-cal2, test\n",
    "    pv_tr, pr_tr = [], []\n",
    "    pv_cal2, pr_cal2 = [], []\n",
    "    pv_te, pr_te = [], []\n",
    "    for v in range(num_views):\n",
    "        p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"ftr\"], cfg.L)\n",
    "        pv_tr.append(p); pr_tr.append(pr)\n",
    "        p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"fcal\"], cfg.L)\n",
    "        pv_cal2.append(p); pr_cal2.append(pr)\n",
    "        p, pr = per_view_pvalues_and_probs(models[v], cal_classwise[v], loaders[v][\"te\"], cfg.L)\n",
    "        pv_te.append(p); pr_te.append(pr)\n",
    "\n",
    "    # Fusion features\n",
    "    X_ftr   = build_fusion_features(pv_tr, pr_tr)\n",
    "    X_fcal2 = build_fusion_features(pv_cal2, pr_cal2)\n",
    "    X_ftest = build_fusion_features(pv_te, pr_te)\n",
    "    d_in = X_ftr.shape[1]\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # (A) Fusion = multinomial LR on [p;prob], then conformalize\n",
    "    # ---------------------------------------------------------\n",
    "    fusion_lr = LogisticRegression(\n",
    "        max_iter=cfg.max_iter_lr,\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    fusion_lr.fit(X_ftr, y_fuse_tr)\n",
    "\n",
    "    fused_probs_cal_lr  = fusion_lr.predict_proba(X_fcal2)\n",
    "    fused_cal_scores_lr = fused_class_cal_scores(y_fuse_cal, fused_probs_cal_lr, cfg.L)\n",
    "    fused_probs_test_lr = fusion_lr.predict_proba(X_ftest)\n",
    "    P_fused_lr          = fused_p_values_from_cal(fused_probs_test_lr, fused_cal_scores_lr)\n",
    "\n",
    "    cov_lr, set_lr = eval_sets_from_pvals(P_fused_lr, Y_test_full, cfg.alpha)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # (B) Fusion = 2-hidden-layer MLP on [p;prob], conformalize\n",
    "    # ---------------------------------------------------------\n",
    "    fusion_mlp = train_fusion_mlp(X_ftr, y_fuse_tr, d_in=d_in, L=cfg.L, seed=seed)\n",
    "    fused_probs_cal_mlp  = fusion_mlp_predict_proba(fusion_mlp, X_fcal2)\n",
    "    fused_cal_scores_mlp = fused_class_cal_scores(y_fuse_cal, fused_probs_cal_mlp, cfg.L)\n",
    "    fused_probs_test_mlp = fusion_mlp_predict_proba(fusion_mlp, X_ftest)\n",
    "    P_fused_mlp          = fused_p_values_from_cal(fused_probs_test_mlp, fused_cal_scores_mlp)\n",
    "\n",
    "    cov_mlp, set_mlp = eval_sets_from_pvals(P_fused_mlp, Y_test_full, cfg.alpha)\n",
    "\n",
    "    return {\n",
    "        \"sim\": sim,\n",
    "        \"LR_cov(%)\": 100.0 * cov_lr,\n",
    "        \"LR_set\": set_lr,\n",
    "        \"MLP_cov(%)\": 100.0 * cov_mlp,\n",
    "        \"MLP_set\": set_mlp,\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Run all sims + print small table\n",
    "# =============================================================================\n",
    "\n",
    "rows = []\n",
    "for sim in range(cfg.num_simulations):\n",
    "    rows.append(run_one_sim(sim))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "def mean_std_str(x: pd.Series) -> str:\n",
    "    return f\"{x.mean():.2f} ({x.std(ddof=1):.2f})\"\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"Method\": [\"Fusion LR\", \"Fusion 2-layer MLP\"],\n",
    "    \"Coverage (%)\": [mean_std_str(df[\"LR_cov(%)\"]), mean_std_str(df[\"MLP_cov(%)\"])],\n",
    "    \"Avg set size\": [mean_std_str(df[\"LR_set\"]), mean_std_str(df[\"MLP_set\"])],\n",
    "})\n",
    "\n",
    "print(\"\\n=== Per-simulation raw results ===\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\n=== Summary over simulations (mean (std)) ===\")\n",
    "print(summary)\n",
    "\n",
    "# Optional: save\n",
    "summary.to_csv(\"fusion_arch_ablation_k4_summary.csv\", index=False)\n",
    "df.to_csv(\"fusion_arch_ablation_k4_raw.csv\", index=False)\n",
    "print(\"\\nSaved: fusion_arch_ablation_k4_summary.csv, fusion_arch_ablation_k4_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490012a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
