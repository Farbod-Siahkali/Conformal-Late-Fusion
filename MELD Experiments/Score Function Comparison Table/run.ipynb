{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dd5580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siahkali/.local/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/siahkali/.local/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA A30\n",
      "Available GPUs: 1\n",
      "Loading RoBERTa tokenizer...\n",
      "\n",
      "Loading data from: /depot/gupta869/data/farbod/preprocessed_data\n",
      "Loading labels for stratification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train labels: 100%|██████████| 11096/11096 [03:34<00:00, 51.73it/s]\n",
      "Loading test labels: 100%|██████████| 2610/2610 [00:49<00:00, 52.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      " Train samples: 11096\n",
      " Test samples:  2610\n",
      " neutral   : 5178 (46.7%)\n",
      " joy       : 1906 (17.2%)\n",
      " surprise  : 1355 (12.2%)\n",
      " anger     : 1262 (11.4%)\n",
      " sadness   :  794 (7.2%)\n",
      " disgust   :  293 (2.6%)\n",
      " fear      :  308 (2.8%)\n",
      "\n",
      "Experiment Configuration:\n",
      " Device: cuda\n",
      " Epochs: Text=10, Audio=20, Video=20\n",
      " LRs:    Text=5e-05, Audio=0.001, Video=0.001\n",
      " Batch size: 64 (train), 8 (inf)\n",
      " Weight decay: 0.01 | Label smoothing: 0.0\n",
      " Sims: 10\n",
      "\n",
      "============================================================\n",
      "Simulation 1/10\n",
      "============================================================\n",
      "\n",
      " [Text (RoBERTa)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/10: Loss=1.400, Train Acc=52.5%, F1=0.466 | Val Acc=59.6%, F1=0.577 | Best F1=0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.172, Train Acc=62.1%, F1=0.590 | Val Acc=62.0%, F1=0.596 | Best F1=0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/10: Loss=0.720, Train Acc=77.1%, F1=0.761 | Val Acc=58.7%, F1=0.586 | Best F1=0.596\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=62.01%, F1=0.5958\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.819, Train Acc=30.7%, F1=0.289 | Val Acc=40.8%, F1=0.312 | Best F1=0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.594, Train Acc=45.3%, F1=0.309 | Val Acc=46.2%, F1=0.308 | Best F1=0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.586, Train Acc=45.7%, F1=0.305 | Val Acc=46.7%, F1=0.297 | Best F1=0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.572, Train Acc=46.0%, F1=0.303 | Val Acc=46.7%, F1=0.297 | Best F1=0.312\n",
      " Early stopping\n",
      " [Audio (CNN)] Best Val: Acc=40.81%, F1=0.3119\n",
      "\n",
      " [Video (ResNet34)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.882, Train Acc=25.9%, F1=0.272 | Val Acc=36.2%, F1=0.310 | Best F1=0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.606, Train Acc=44.9%, F1=0.308 | Val Acc=46.7%, F1=0.297 | Best F1=0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.579, Train Acc=45.9%, F1=0.304 | Val Acc=46.7%, F1=0.297 | Best F1=0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.577, Train Acc=46.1%, F1=0.301 | Val Acc=46.6%, F1=0.297 | Best F1=0.310\n",
      " Early stopping\n",
      " [Video (ResNet34)] Best Val: Acc=36.19%, F1=0.3102\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: hinge\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (hinge):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  61.72% | Audio: 41.30% | Video: 37.59%\n",
      " Fusion Accuracies: Avg Ensemble 61.03% | Learned Fusion 63.30%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.23% | set= 4.35\n",
      " MinPV:  cov=91.26% | set= 5.57\n",
      " Fisher: cov=90.84% | set= 5.35\n",
      " AdjFis: cov=90.15% | set= 5.07\n",
      " WAvgL:  cov=99.31% | set= 6.78\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: margin\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (margin):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  61.72% | Audio: 41.30% | Video: 37.59%\n",
      " Fusion Accuracies: Avg Ensemble 61.03% | Learned Fusion 63.33%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.77% | set= 4.57\n",
      " MinPV:  cov=90.00% | set= 5.61\n",
      " Fisher: cov=90.92% | set= 5.40\n",
      " AdjFis: cov=90.08% | set= 5.08\n",
      " WAvgL:  cov=99.50% | set= 6.78\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: cross_entropy\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (cross_entropy):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  61.72% | Audio: 41.30% | Video: 37.59%\n",
      " Fusion Accuracies: Avg Ensemble 61.03% | Learned Fusion 63.30%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.23% | set= 4.35\n",
      " MinPV:  cov=91.26% | set= 5.57\n",
      " Fisher: cov=90.84% | set= 5.35\n",
      " AdjFis: cov=90.15% | set= 5.07\n",
      " WAvgL:  cov=99.31% | set= 6.78\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: raps\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (raps):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  61.72% | Audio: 41.30% | Video: 37.59%\n",
      " Fusion Accuracies: Avg Ensemble 61.03% | Learned Fusion 63.26%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.43% | set= 4.33\n",
      " MinPV:  cov=92.45% | set= 5.84\n",
      " Fisher: cov=92.03% | set= 5.58\n",
      " AdjFis: cov=91.03% | set= 5.29\n",
      " WAvgL:  cov=99.35% | set= 6.79\n",
      " ==================================================\n",
      "\n",
      "============================================================\n",
      "Simulation 2/10\n",
      "============================================================\n",
      "\n",
      " [Text (RoBERTa)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/10: Loss=1.408, Train Acc=52.0%, F1=0.462 | Val Acc=63.2%, F1=0.601 | Best F1=0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.154, Train Acc=62.6%, F1=0.593 | Val Acc=63.5%, F1=0.608 | Best F1=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.021, Train Acc=66.6%, F1=0.640 | Val Acc=60.9%, F1=0.597 | Best F1=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.857, Train Acc=72.5%, F1=0.711 | Val Acc=63.7%, F1=0.632 | Best F1=0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/10: Loss=0.684, Train Acc=78.4%, F1=0.777 | Val Acc=62.2%, F1=0.611 | Best F1=0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6/10: Loss=0.537, Train Acc=83.4%, F1=0.830 | Val Acc=59.6%, F1=0.602 | Best F1=0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7/10: Loss=0.407, Train Acc=87.3%, F1=0.871 | Val Acc=61.3%, F1=0.611 | Best F1=0.632\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=63.70%, F1=0.6316\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.885, Train Acc=25.6%, F1=0.269 | Val Acc=46.0%, F1=0.306 | Best F1=0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.604, Train Acc=45.0%, F1=0.311 | Val Acc=45.0%, F1=0.326 | Best F1=0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.585, Train Acc=45.8%, F1=0.310 | Val Acc=46.7%, F1=0.297 | Best F1=0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.569, Train Acc=46.3%, F1=0.314 | Val Acc=46.8%, F1=0.300 | Best F1=0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/20: Loss=1.561, Train Acc=46.1%, F1=0.312 | Val Acc=46.7%, F1=0.297 | Best F1=0.326\n",
      " Early stopping\n",
      " [Audio (CNN)] Best Val: Acc=44.98%, F1=0.3261\n",
      "\n",
      " [Video (ResNet34)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.788, Train Acc=31.4%, F1=0.299 | Val Acc=45.0%, F1=0.302 | Best F1=0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.603, Train Acc=45.3%, F1=0.306 | Val Acc=44.3%, F1=0.313 | Best F1=0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.592, Train Acc=46.0%, F1=0.301 | Val Acc=43.3%, F1=0.293 | Best F1=0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.575, Train Acc=46.2%, F1=0.300 | Val Acc=46.7%, F1=0.297 | Best F1=0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/20: Loss=1.568, Train Acc=46.5%, F1=0.301 | Val Acc=46.7%, F1=0.297 | Best F1=0.313\n",
      " Early stopping\n",
      " [Video (ResNet34)] Best Val: Acc=44.31%, F1=0.3131\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: hinge\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (hinge):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  61.23% | Audio: 46.36% | Video: 45.13%\n",
      " Fusion Accuracies: Avg Ensemble 60.69% | Learned Fusion 63.03%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.50% | set= 4.42\n",
      " MinPV:  cov=91.72% | set= 5.88\n",
      " Fisher: cov=90.38% | set= 5.45\n",
      " AdjFis: cov=89.12% | set= 5.22\n",
      " WAvgL:  cov=99.46% | set= 6.75\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: margin\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (margin):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  61.23% | Audio: 46.36% | Video: 45.13%\n",
      " Fusion Accuracies: Avg Ensemble 60.69% | Learned Fusion 62.76%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.77% | set= 4.64\n",
      " MinPV:  cov=93.33% | set= 6.12\n",
      " Fisher: cov=92.11% | set= 5.72\n",
      " AdjFis: cov=89.96% | set= 5.34\n",
      " WAvgL:  cov=99.39% | set= 6.83\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: cross_entropy\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/10: Loss=1.403, Train Acc=51.5%, F1=0.466 | Val Acc=62.7%, F1=0.592 | Best F1=0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.147, Train Acc=62.8%, F1=0.598 | Val Acc=61.1%, F1=0.588 | Best F1=0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.011, Train Acc=67.1%, F1=0.648 | Val Acc=62.8%, F1=0.587 | Best F1=0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.843, Train Acc=73.0%, F1=0.714 | Val Acc=61.9%, F1=0.610 | Best F1=0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/10: Loss=0.680, Train Acc=78.5%, F1=0.778 | Val Acc=60.3%, F1=0.598 | Best F1=0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6/10: Loss=0.544, Train Acc=83.0%, F1=0.827 | Val Acc=60.8%, F1=0.602 | Best F1=0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7/10: Loss=0.425, Train Acc=86.4%, F1=0.862 | Val Acc=59.9%, F1=0.593 | Best F1=0.610\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=61.89%, F1=0.6101\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.816, Train Acc=29.7%, F1=0.293 | Val Acc=46.7%, F1=0.297 | Best F1=0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.609, Train Acc=45.2%, F1=0.311 | Val Acc=46.3%, F1=0.312 | Best F1=0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.588, Train Acc=46.0%, F1=0.311 | Val Acc=47.4%, F1=0.324 | Best F1=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.568, Train Acc=46.3%, F1=0.311 | Val Acc=46.7%, F1=0.297 | Best F1=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/20: Loss=1.557, Train Acc=46.1%, F1=0.307 | Val Acc=43.7%, F1=0.301 | Best F1=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6/20: Loss=1.553, Train Acc=46.3%, F1=0.310 | Val Acc=46.9%, F1=0.326 | Best F1=0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7/20: Loss=1.550, Train Acc=46.3%, F1=0.309 | Val Acc=46.7%, F1=0.297 | Best F1=0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8/20: Loss=1.548, Train Acc=46.3%, F1=0.305 | Val Acc=46.3%, F1=0.297 | Best F1=0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9/20: Loss=1.546, Train Acc=46.4%, F1=0.313 | Val Acc=47.7%, F1=0.346 | Best F1=0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10/20: Loss=1.537, Train Acc=46.6%, F1=0.308 | Val Acc=46.7%, F1=0.297 | Best F1=0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11/20: Loss=1.537, Train Acc=46.5%, F1=0.304 | Val Acc=46.7%, F1=0.298 | Best F1=0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12/20: Loss=1.533, Train Acc=46.6%, F1=0.312 | Val Acc=46.8%, F1=0.306 | Best F1=0.346\n",
      " Early stopping\n",
      " [Audio (CNN)] Best Val: Acc=47.69%, F1=0.3465\n",
      "\n",
      " [Video (ResNet34)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.926, Train Acc=25.0%, F1=0.259 | Val Acc=46.7%, F1=0.300 | Best F1=0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.610, Train Acc=44.7%, F1=0.308 | Val Acc=46.7%, F1=0.297 | Best F1=0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.589, Train Acc=45.9%, F1=0.301 | Val Acc=46.7%, F1=0.297 | Best F1=0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.571, Train Acc=46.4%, F1=0.302 | Val Acc=46.7%, F1=0.297 | Best F1=0.300\n",
      " Early stopping\n",
      " [Video (ResNet34)] Best Val: Acc=46.67%, F1=0.3004\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: hinge\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (hinge):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  62.68% | Audio: 47.28% | Video: 47.85%\n",
      " Fusion Accuracies: Avg Ensemble 61.49% | Learned Fusion 63.41%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=91.46% | set= 4.66\n",
      " MinPV:  cov=90.80% | set= 5.71\n",
      " Fisher: cov=89.58% | set= 4.98\n",
      " AdjFis: cov=89.50% | set= 4.74\n",
      " WAvgL:  cov=98.89% | set= 6.64\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: margin\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (margin):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  62.68% | Audio: 47.28% | Video: 47.85%\n",
      " Fusion Accuracies: Avg Ensemble 61.49% | Learned Fusion 64.02%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=91.30% | set= 4.77\n",
      " MinPV:  cov=90.31% | set= 5.97\n",
      " Fisher: cov=89.89% | set= 5.37\n",
      " AdjFis: cov=89.08% | set= 5.17\n",
      " WAvgL:  cov=99.31% | set= 6.78\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: cross_entropy\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (cross_entropy):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  62.68% | Audio: 47.28% | Video: 47.85%\n",
      " Fusion Accuracies: Avg Ensemble 61.49% | Learned Fusion 63.41%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=91.46% | set= 4.66\n",
      " MinPV:  cov=90.80% | set= 5.71\n",
      " Fisher: cov=89.58% | set= 4.98\n",
      " AdjFis: cov=89.50% | set= 4.74\n",
      " WAvgL:  cov=98.89% | set= 6.64\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: raps\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (raps):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  62.68% | Audio: 47.28% | Video: 47.85%\n",
      " Fusion Accuracies: Avg Ensemble 61.49% | Learned Fusion 63.14%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=91.23% | set= 4.98\n",
      " MinPV:  cov=91.03% | set= 5.76\n",
      " Fisher: cov=90.54% | set= 5.17\n",
      " AdjFis: cov=90.08% | set= 4.95\n",
      " WAvgL:  cov=99.31% | set= 6.71\n",
      " ==================================================\n",
      "\n",
      "============================================================\n",
      "Simulation 4/10\n",
      "============================================================\n",
      "\n",
      " [Text (RoBERTa)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/10: Loss=1.408, Train Acc=52.7%, F1=0.474 | Val Acc=58.2%, F1=0.554 | Best F1=0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.029, Train Acc=67.1%, F1=0.646 | Val Acc=58.9%, F1=0.573 | Best F1=0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.891, Train Acc=71.5%, F1=0.698 | Val Acc=59.5%, F1=0.576 | Best F1=0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/10: Loss=0.723, Train Acc=77.5%, F1=0.765 | Val Acc=57.3%, F1=0.569 | Best F1=0.581\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=60.54%, F1=0.5814\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.763, Train Acc=34.0%, F1=0.304 | Val Acc=46.7%, F1=0.297 | Best F1=0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.603, Train Acc=45.2%, F1=0.310 | Val Acc=46.7%, F1=0.297 | Best F1=0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.165, Train Acc=62.1%, F1=0.589 | Val Acc=61.9%, F1=0.587 | Best F1=0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|████████  | 84/104 [00:39<00:09,  2.18it/s, loss=0.898, grad_norm=7.70] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.037, Train Acc=66.4%, F1=0.640 | Val Acc=62.1%, F1=0.587 | Best F1=0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.880, Train Acc=72.4%, F1=0.704 | Val Acc=56.7%, F1=0.565 | Best F1=0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/10: Loss=0.721, Train Acc=77.2%, F1=0.762 | Val Acc=58.2%, F1=0.566 | Best F1=0.587\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=61.89%, F1=0.5870\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.856, Train Acc=27.6%, F1=0.274 | Val Acc=40.1%, F1=0.324 | Best F1=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6/20: Loss=1.554, Train Acc=46.3%, F1=0.300 | Val Acc=46.7%, F1=0.297 | Best F1=0.304\n",
      " Early stopping\n",
      " [Video (ResNet34)] Best Val: Acc=46.45%, F1=0.3037\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: hinge\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (hinge):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.22% | Audio: 38.70% | Video: 47.97%\n",
      " Fusion Accuracies: Avg Ensemble 59.35% | Learned Fusion 63.83%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.85% | set= 4.34\n",
      " MinPV:  cov=93.37% | set= 5.94\n",
      " Fisher: cov=91.53% | set= 5.49\n",
      " AdjFis: cov=90.46% | set= 5.30\n",
      " WAvgL:  cov=99.35% | set= 6.76\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: margin\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (margin):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.22% | Audio: 38.70% | Video: 47.97%\n",
      " Fusion Accuracies: Avg Ensemble 59.35% | Learned Fusion 63.79%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.43% | set= 4.50\n",
      " MinPV:  cov=92.53% | set= 6.08\n",
      " Fisher: cov=90.80% | set= 5.60\n",
      " AdjFis: cov=90.11% | set= 5.45\n",
      " WAvgL:  cov=99.08% | set= 6.78\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: cross_entropy\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (cross_entropy):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.22% | Audio: 38.70% | Video: 47.97%\n",
      " Fusion Accuracies: Avg Ensemble 59.35% | Learned Fusion 63.83%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.85% | set= 4.34\n",
      " MinPV:  cov=93.37% | set= 5.94\n",
      " Fisher: cov=91.53% | set= 5.49\n",
      " AdjFis: cov=90.46% | set= 5.30\n",
      " WAvgL:  cov=99.35% | set= 6.76\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: raps\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (raps):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.22% | Audio: 38.70% | Video: 47.97%\n",
      " Fusion Accuracies: Avg Ensemble 59.35% | Learned Fusion 63.91%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.11% | set= 4.36\n",
      " MinPV:  cov=91.95% | set= 5.98\n",
      " Fisher: cov=91.88% | set= 5.63\n",
      " AdjFis: cov=91.00% | set= 5.38\n",
      " WAvgL:  cov=99.43% | set= 6.80\n",
      " ==================================================\n",
      "\n",
      "============================================================\n",
      "Simulation 6/10\n",
      "============================================================\n",
      "\n",
      " [Text (RoBERTa)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/10: Loss=1.404, Train Acc=52.7%, F1=0.464 | Val Acc=62.8%, F1=0.606 | Best F1=0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.150, Train Acc=62.4%, F1=0.593 | Val Acc=60.3%, F1=0.553 | Best F1=0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.020, Train Acc=66.8%, F1=0.644 | Val Acc=62.5%, F1=0.598 | Best F1=0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.858, Train Acc=71.9%, F1=0.705 | Val Acc=59.2%, F1=0.578 | Best F1=0.606\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=62.80%, F1=0.6057\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.754, Train Acc=34.0%, F1=0.315 | Val Acc=45.8%, F1=0.323 | Best F1=0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.606, Train Acc=44.9%, F1=0.317 | Val Acc=46.7%, F1=0.297 | Best F1=0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.583, Train Acc=45.4%, F1=0.308 | Val Acc=46.7%, F1=0.297 | Best F1=0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.567, Train Acc=46.1%, F1=0.306 | Val Acc=46.7%, F1=0.297 | Best F1=0.323\n",
      " Early stopping\n",
      " [Audio (CNN)] Best Val: Acc=45.77%, F1=0.3228\n",
      "\n",
      " [Video (ResNet34)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.848, Train Acc=28.9%, F1=0.281 | Val Acc=45.7%, F1=0.304 | Best F1=0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.594, Train Acc=45.6%, F1=0.307 | Val Acc=46.7%, F1=0.297 | Best F1=0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.585, Train Acc=46.1%, F1=0.302 | Val Acc=46.7%, F1=0.297 | Best F1=0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.573, Train Acc=46.3%, F1=0.301 | Val Acc=45.4%, F1=0.296 | Best F1=0.304\n",
      " Early stopping\n",
      " [Video (ResNet34)] Best Val: Acc=45.66%, F1=0.3043\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: hinge\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (hinge):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.30% | Audio: 47.16% | Video: 46.21%\n",
      " Fusion Accuracies: Avg Ensemble 58.58% | Learned Fusion 63.98%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.23% | set= 4.74\n",
      " MinPV:  cov=91.61% | set= 5.78\n",
      " Fisher: cov=90.23% | set= 5.40\n",
      " AdjFis: cov=89.77% | set= 5.15\n",
      " WAvgL:  cov=99.23% | set= 6.68\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: margin\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (margin):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.30% | Audio: 47.16% | Video: 46.21%\n",
      " Fusion Accuracies: Avg Ensemble 58.58% | Learned Fusion 64.41%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.81% | set= 4.76\n",
      " MinPV:  cov=92.84% | set= 6.01\n",
      " Fisher: cov=90.31% | set= 5.50\n",
      " AdjFis: cov=89.46% | set= 5.35\n",
      " WAvgL:  cov=99.35% | set= 6.79\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: cross_entropy\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (cross_entropy):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.30% | Audio: 47.16% | Video: 46.21%\n",
      " Fusion Accuracies: Avg Ensemble 58.58% | Learned Fusion 63.98%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=89.23% | set= 4.74\n",
      " MinPV:  cov=91.61% | set= 5.78\n",
      " Fisher: cov=90.23% | set= 5.40\n",
      " AdjFis: cov=89.77% | set= 5.15\n",
      " WAvgL:  cov=99.23% | set= 6.68\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: raps\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (raps):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.30% | Audio: 47.16% | Video: 46.21%\n",
      " Fusion Accuracies: Avg Ensemble 58.58% | Learned Fusion 63.64%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.77% | set= 4.87\n",
      " MinPV:  cov=92.45% | set= 5.97\n",
      " Fisher: cov=91.84% | set= 5.57\n",
      " AdjFis: cov=90.11% | set= 5.30\n",
      " WAvgL:  cov=99.54% | set= 6.78\n",
      " ==================================================\n",
      "\n",
      "============================================================\n",
      "Simulation 7/10\n",
      "============================================================\n",
      "\n",
      " [Text (RoBERTa)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/10: Loss=1.415, Train Acc=51.1%, F1=0.449 | Val Acc=60.2%, F1=0.544 | Best F1=0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.175, Train Acc=61.7%, F1=0.583 | Val Acc=61.2%, F1=0.581 | Best F1=0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.042, Train Acc=66.6%, F1=0.640 | Val Acc=64.3%, F1=0.608 | Best F1=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.876, Train Acc=71.7%, F1=0.701 | Val Acc=62.8%, F1=0.609 | Best F1=0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.814, Train Acc=30.9%, F1=0.303 | Val Acc=46.7%, F1=0.298 | Best F1=0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.599, Train Acc=45.5%, F1=0.313 | Val Acc=46.7%, F1=0.297 | Best F1=0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.572, Train Acc=46.1%, F1=0.308 | Val Acc=44.8%, F1=0.304 | Best F1=0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.560, Train Acc=46.2%, F1=0.317 | Val Acc=46.7%, F1=0.297 | Best F1=0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/20: Loss=1.550, Train Acc=46.2%, F1=0.310 | Val Acc=46.4%, F1=0.302 | Best F1=0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6/20: Loss=1.544, Train Acc=46.3%, F1=0.314 | Val Acc=46.4%, F1=0.303 | Best F1=0.304\n",
      " Early stopping\n",
      " [Audio (CNN)] Best Val: Acc=44.76%, F1=0.3040\n",
      "\n",
      " [Video (ResNet34)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.878, Train Acc=25.5%, F1=0.267 | Val Acc=45.3%, F1=0.298 | Best F1=0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.600, Train Acc=45.6%, F1=0.307 | Val Acc=45.9%, F1=0.295 | Best F1=0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.582, Train Acc=46.0%, F1=0.299 | Val Acc=46.7%, F1=0.297 | Best F1=0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.576, Train Acc=46.2%, F1=0.298 | Val Acc=46.7%, F1=0.297 | Best F1=0.298\n",
      " Early stopping\n",
      " [Video (ResNet34)] Best Val: Acc=45.32%, F1=0.2984\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: hinge\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (hinge):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.37% | Audio: 47.97% | Video: 46.44%\n",
      " Fusion Accuracies: Avg Ensemble 60.46% | Learned Fusion 63.60%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.31% | set= 4.50\n",
      " MinPV:  cov=92.30% | set= 5.72\n",
      " Fisher: cov=91.72% | set= 5.43\n",
      " AdjFis: cov=91.07% | set= 5.20\n",
      " WAvgL:  cov=98.97% | set= 6.76\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: margin\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (margin):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.37% | Audio: 47.97% | Video: 46.44%\n",
      " Fusion Accuracies: Avg Ensemble 60.46% | Learned Fusion 63.07%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.57% | set= 4.80\n",
      " MinPV:  cov=90.65% | set= 5.84\n",
      " Fisher: cov=91.15% | set= 5.53\n",
      " AdjFis: cov=90.15% | set= 5.41\n",
      " WAvgL:  cov=99.43% | set= 6.77\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: cross_entropy\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (cross_entropy):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.37% | Audio: 47.97% | Video: 46.44%\n",
      " Fusion Accuracies: Avg Ensemble 60.46% | Learned Fusion 63.60%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.31% | set= 4.50\n",
      " MinPV:  cov=92.30% | set= 5.72\n",
      " Fisher: cov=91.72% | set= 5.43\n",
      " AdjFis: cov=91.07% | set= 5.20\n",
      " WAvgL:  cov=98.97% | set= 6.76\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: raps\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (raps):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.37% | Audio: 47.97% | Video: 46.44%\n",
      " Fusion Accuracies: Avg Ensemble 60.46% | Learned Fusion 62.95%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.84% | set= 4.78\n",
      " MinPV:  cov=92.07% | set= 5.95\n",
      " Fisher: cov=92.11% | set= 5.64\n",
      " AdjFis: cov=91.46% | set= 5.37\n",
      " WAvgL:  cov=99.16% | set= 6.82\n",
      " ==================================================\n",
      "\n",
      "============================================================\n",
      "Simulation 8/10\n",
      "============================================================\n",
      "\n",
      " [Text (RoBERTa)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/10: Loss=1.390, Train Acc=52.2%, F1=0.459 | Val Acc=59.6%, F1=0.586 | Best F1=0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.180, Train Acc=61.5%, F1=0.583 | Val Acc=63.4%, F1=0.593 | Best F1=0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.038, Train Acc=66.7%, F1=0.639 | Val Acc=64.6%, F1=0.621 | Best F1=0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.856, Train Acc=72.8%, F1=0.710 | Val Acc=60.1%, F1=0.589 | Best F1=0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/10: Loss=0.708, Train Acc=77.4%, F1=0.762 | Val Acc=55.8%, F1=0.567 | Best F1=0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6/10: Loss=0.556, Train Acc=82.2%, F1=0.819 | Val Acc=60.1%, F1=0.593 | Best F1=0.621\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=64.60%, F1=0.6212\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.785, Train Acc=32.7%, F1=0.303 | Val Acc=45.7%, F1=0.322 | Best F1=0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.597, Train Acc=45.1%, F1=0.316 | Val Acc=41.5%, F1=0.324 | Best F1=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.584, Train Acc=45.8%, F1=0.309 | Val Acc=46.7%, F1=0.297 | Best F1=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.574, Train Acc=46.2%, F1=0.300 | Val Acc=46.7%, F1=0.297 | Best F1=0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/20: Loss=1.560, Train Acc=46.5%, F1=0.298 | Val Acc=46.7%, F1=0.297 | Best F1=0.324\n",
      " Early stopping\n",
      " [Audio (CNN)] Best Val: Acc=41.49%, F1=0.3237\n",
      "\n",
      " [Video (ResNet34)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.818, Train Acc=30.1%, F1=0.287 | Val Acc=44.5%, F1=0.316 | Best F1=0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.613, Train Acc=45.2%, F1=0.311 | Val Acc=39.8%, F1=0.306 | Best F1=0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/20: Loss=1.590, Train Acc=45.8%, F1=0.302 | Val Acc=46.7%, F1=0.297 | Best F1=0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/20: Loss=1.579, Train Acc=46.3%, F1=0.302 | Val Acc=46.7%, F1=0.297 | Best F1=0.316\n",
      " Early stopping\n",
      " [Video (ResNet34)] Best Val: Acc=44.53%, F1=0.3163\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: hinge\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (hinge):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  64.21% | Audio: 40.54% | Video: 44.75%\n",
      " Fusion Accuracies: Avg Ensemble 60.31% | Learned Fusion 63.45%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.00% | set= 4.15\n",
      " MinPV:  cov=91.80% | set= 5.83\n",
      " Fisher: cov=90.15% | set= 5.56\n",
      " AdjFis: cov=88.89% | set= 5.20\n",
      " WAvgL:  cov=99.35% | set= 6.79\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: margin\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (margin):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  64.21% | Audio: 40.54% | Video: 44.75%\n",
      " Fusion Accuracies: Avg Ensemble 60.31% | Learned Fusion 63.75%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.23% | set= 4.26\n",
      " MinPV:  cov=91.38% | set= 5.99\n",
      " Fisher: cov=89.73% | set= 5.59\n",
      " AdjFis: cov=88.93% | set= 5.28\n",
      " WAvgL:  cov=99.31% | set= 6.78\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: cross_entropy\n",
      "------------------------------------------------------------\n",
      " Training fusion model...\n",
      "\n",
      " Results Summary (cross_entropy):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  64.21% | Audio: 40.54% | Video: 44.75%\n",
      " Fusion Accuracies: Avg Ensemble 60.31% | Learned Fusion 63.45%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.00% | set= 4.15\n",
      " MinPV:  cov=91.80% | set= 5.83\n",
      " Fisher: cov=90.15% | set= 5.56\n",
      " AdjFis: cov=88.89% | set= 5.20\n",
      " WAvgL:  cov=99.35% | set= 6.79\n",
      " ==================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score Function: raps\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/10: Loss=1.146, Train Acc=63.0%, F1=0.601 | Val Acc=60.2%, F1=0.580 | Best F1=0.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3/10: Loss=1.014, Train Acc=67.5%, F1=0.650 | Val Acc=61.4%, F1=0.597 | Best F1=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4/10: Loss=0.854, Train Acc=72.7%, F1=0.709 | Val Acc=59.5%, F1=0.579 | Best F1=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5/10: Loss=0.696, Train Acc=77.6%, F1=0.765 | Val Acc=61.4%, F1=0.603 | Best F1=0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6/10: Loss=0.549, Train Acc=82.6%, F1=0.822 | Val Acc=59.9%, F1=0.580 | Best F1=0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7/10: Loss=0.430, Train Acc=86.7%, F1=0.865 | Val Acc=58.9%, F1=0.586 | Best F1=0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8/10: Loss=0.353, Train Acc=89.4%, F1=0.893 | Val Acc=58.6%, F1=0.585 | Best F1=0.603\n",
      " Early stopping\n",
      " [Text (RoBERTa)] Best Val: Acc=61.44%, F1=0.6030\n",
      "\n",
      " [Audio (CNN)] Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1/20: Loss=1.822, Train Acc=29.7%, F1=0.289 | Val Acc=46.7%, F1=0.297 | Best F1=0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2/20: Loss=1.599, Train Acc=44.8%, F1=0.306 | Val Acc=46.7%, F1=0.297 | Best F1=0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 100/104 [00:14<00:00,  7.06it/s, loss=1.525, grad_norm=2.13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training fusion model...\n",
      "\n",
      " Results Summary (raps):\n",
      " ==================================================\n",
      " Individual Accuracies:\n",
      " Text:  63.72% | Audio: 41.61% | Video: 43.68%\n",
      " Fusion Accuracies: Avg Ensemble 60.61% | Learned Fusion 64.25%\n",
      " Conformal Metrics (target 90%):\n",
      " CF:     cov=90.38% | set= 4.36\n",
      " MinPV:  cov=91.38% | set= 5.93\n",
      " Fisher: cov=91.42% | set= 5.43\n",
      " AdjFis: cov=91.38% | set= 5.35\n",
      " WAvgL:  cov=99.46% | set= 6.77\n",
      " ==================================================\n",
      "\n",
      "=== Coverage (raw rows) ===\n",
      "           Score  Sim  K  Conformal Fusion  Min p-Value     Fisher  \\\n",
      "0          hinge    0  3         90.229885    91.264368  90.842912   \n",
      "1         margin    0  3         89.770115    90.000000  90.919540   \n",
      "2  cross_entropy    0  3         90.229885    91.264368  90.842912   \n",
      "3           raps    0  3         89.425287    92.452107  92.030651   \n",
      "4          hinge    1  3         90.498084    91.724138  90.383142   \n",
      "\n",
      "   Adjusted Fisher  Weighted Avg (learned)  \n",
      "0        90.153257               99.310345  \n",
      "1        90.076628               99.501916  \n",
      "2        90.153257               99.310345  \n",
      "3        91.034483               99.348659  \n",
      "4        89.118774               99.463602  \n",
      "\n",
      "=== Set Size (raw rows) ===\n",
      "           Score  Sim  K  Conformal Fusion  Min p-Value    Fisher  \\\n",
      "0          hinge    0  3          4.349425     5.571264  5.354023   \n",
      "1         margin    0  3          4.567816     5.609962  5.401916   \n",
      "2  cross_entropy    0  3          4.349425     5.571264  5.354023   \n",
      "3           raps    0  3          4.333716     5.839847  5.577395   \n",
      "4          hinge    1  3          4.418391     5.876628  5.447510   \n",
      "\n",
      "   Adjusted Fisher  Weighted Avg (learned)  \n",
      "0         5.066667                6.778161  \n",
      "1         5.079310                6.777395  \n",
      "2         5.066667                6.778161  \n",
      "3         5.288123                6.793487  \n",
      "4         5.218008                6.749808  \n",
      "\n",
      "=== Accuracy (raw rows) ===\n",
      "           Score  Sim  K  Fused Acc  Average Acc   Text Acc  Audio Acc  \\\n",
      "0          hinge    0  3  63.295019    61.034483  61.724138  41.302682   \n",
      "1         margin    0  3  63.333333    61.034483  61.724138  41.302682   \n",
      "2  cross_entropy    0  3  63.295019    61.034483  61.724138  41.302682   \n",
      "3           raps    0  3  63.256705    61.034483  61.724138  41.302682   \n",
      "4          hinge    1  3  63.026820    60.689655  61.226054  46.360153   \n",
      "\n",
      "   Video Acc  \n",
      "0  37.586207  \n",
      "1  37.586207  \n",
      "2  37.586207  \n",
      "3  37.586207  \n",
      "4  45.134100  \n",
      "\n",
      "Saved:\n",
      " - meld_summary_coverage.csv/tex\n",
      " - meld_summary_setsize.csv/tex\n",
      " - meld_summary_final.csv/tex\n",
      " - meld_accuracy_summary.csv/tex\n"
     ]
    }
   ],
   "source": [
    "# A single, complete script: Multimodal MELD + score-function baselines\n",
    "# Trains per-view models once per simulation, then loops\n",
    "# over score functions (hinge/margin/cross_entropy/raps) to match your first\n",
    "# procedure and save comparable tables.\n",
    "#\n",
    "# NOTE: MVCP REMOVED (functions, config fields, calibration/eval/logging).\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, models as tv_models\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    RobertaModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==================== Models ====================\n",
    "class ImprovedAudioModel(nn.Module):\n",
    "    \"\"\"Audio CNN for mel-spectrograms w/ GAP, BN, Dropout, residual\"\"\"\n",
    "    def __init__(self, num_classes=7, hidden_dim=512, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2), nn.Dropout2d(0.2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2), nn.Dropout2d(0.2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2), nn.Dropout2d(0.2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_dim // 2, num_classes)\n",
    "\n",
    "    def forward(self, audio_mel, **kwargs):\n",
    "        x = self.conv1(audio_mel)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        identity = x\n",
    "        x = self.dropout(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(F.relu(self.bn2(self.fc2(x))))\n",
    "        if identity.size(1) == x.size(1):\n",
    "            x = x + identity\n",
    "        x = self.dropout(F.relu(self.bn3(self.fc3(x))))\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class ImprovedVideoModel(nn.Module):\n",
    "    \"\"\"ResNet34 feature extractor (partial freeze) + MLP head\"\"\"\n",
    "    def __init__(self, num_classes=7, hidden_dim=512, dropout=0.4):\n",
    "        super().__init__()\n",
    "        resnet = tv_models.resnet34(weights=tv_models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "        for p in resnet.parameters(): p.requires_grad = False\n",
    "        for p in resnet.layer2.parameters(): p.requires_grad = True\n",
    "        for p in resnet.layer3.parameters(): p.requires_grad = True\n",
    "        for p in resnet.layer4.parameters(): p.requires_grad = True\n",
    "\n",
    "        self.frozen_layers = nn.Sequential(\n",
    "            resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool, resnet.layer1\n",
    "        )\n",
    "        self.trainable_layers = nn.Sequential(\n",
    "            resnet.layer2, resnet.layer3, resnet.layer4, resnet.avgpool\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_dim // 2, num_classes)\n",
    "\n",
    "    def forward(self, face, **kwargs):\n",
    "        self.frozen_layers.eval()\n",
    "        with torch.no_grad():\n",
    "            x = self.frozen_layers(face)\n",
    "        x = self.trainable_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        identity = x\n",
    "        x1 = self.dropout(F.relu(self.bn1(self.fc1(x))))\n",
    "        x2 = self.dropout(F.relu(self.bn2(self.fc2(x1))))\n",
    "        if identity.size(1) == x2.size(1):\n",
    "            x2 = x2 + identity\n",
    "        x3 = self.dropout(F.relu(self.bn3(self.fc3(x2))))\n",
    "        logits = self.classifier(x3)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class ImprovedTextModel(nn.Module):\n",
    "    \"\"\"RoBERTa-base (partial unfreeze) + self-attn pooling + MLP head\"\"\"\n",
    "    def __init__(self, num_classes=7, hidden_dim=768, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.text_encoder = RobertaModel.from_pretrained('roberta-base')\n",
    "        for p in self.text_encoder.parameters(): p.requires_grad = False\n",
    "        for p in self.text_encoder.encoder.layer[-8:].parameters(): p.requires_grad = True\n",
    "        for p in self.text_encoder.pooler.parameters(): p.requires_grad = True\n",
    "\n",
    "        text_dim = 768\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=text_dim, num_heads=4, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc1 = nn.Linear(text_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim // 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_dim // 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, **kwargs):\n",
    "        text_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = text_out.last_hidden_state\n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            hidden_states, hidden_states, hidden_states,\n",
    "            key_padding_mask=(attention_mask == 0)\n",
    "        )\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(attn_output.size()).float()\n",
    "        sum_embeddings = torch.sum(attn_output * mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "        text_features = sum_embeddings / sum_mask\n",
    "        x1 = self.dropout(F.gelu(self.ln1(self.fc1(text_features))))\n",
    "        x2 = self.dropout(F.gelu(self.ln2(self.fc2(x1))))\n",
    "        x3 = self.dropout(F.gelu(self.ln3(self.fc3(x2 + x1))))\n",
    "        logits = self.classifier(x3)\n",
    "        return logits\n",
    "\n",
    "# ==================== Dataset ====================\n",
    "class PreprocessedMELDDataset(Dataset):\n",
    "    def __init__(self, data_dir, tokenizer, max_length=128, files=None, augment=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.augment = augment\n",
    "        self.files = files if files is not None else sorted(\n",
    "            [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.pt')]\n",
    "        )\n",
    "        self.emotion_map = {\n",
    "            'neutral': 0, 'joy': 1, 'surprise': 2, 'anger': 3,\n",
    "            'sadness': 4, 'disgust': 5, 'fear': 6\n",
    "        }\n",
    "\n",
    "    def __len__(self): return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.load(self.files[idx], map_location='cpu')\n",
    "\n",
    "        # text\n",
    "        text = sample['utterance']\n",
    "        encoded = self.tokenizer(\n",
    "            text, padding='max_length', truncation=True,\n",
    "            max_length=self.max_length, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # audio (mel)\n",
    "        audio_mel = sample['audio_mel']\n",
    "        if audio_mel.dim() == 2: audio_mel = audio_mel.unsqueeze(0)\n",
    "        max_audio_len = 300\n",
    "        pad_len = max_audio_len - audio_mel.shape[-1]\n",
    "        if pad_len > 0:\n",
    "            audio_mel = F.pad(audio_mel, (0, pad_len), value=audio_mel.min())\n",
    "        audio_mel = torch.log1p(audio_mel.clamp(min=0))\n",
    "        audio_mel = (audio_mel - audio_mel.mean()) / (audio_mel.std() + 1e-8)\n",
    "        audio_mel = torch.clamp(audio_mel, -3, 3)\n",
    "\n",
    "        # light augmentation\n",
    "        if self.augment and np.random.rand() < 0.3:\n",
    "            if np.random.rand() < 0.5:\n",
    "                t_mask_width = int(audio_mel.shape[-1] * 0.1)\n",
    "                t_start = np.random.randint(0, max(1, audio_mel.shape[-1] - t_mask_width))\n",
    "                audio_mel[..., t_start:t_start + t_mask_width] = audio_mel.min()\n",
    "            if np.random.rand() < 0.5 and audio_mel.shape[-2] > 1:\n",
    "                f_mask_width = int(audio_mel.shape[-2] * 0.1)\n",
    "                f_start = np.random.randint(0, max(1, audio_mel.shape[-2] - f_mask_width))\n",
    "                audio_mel[..., f_start:f_start + f_mask_width, :] = audio_mel.min()\n",
    "\n",
    "        # face image\n",
    "        face = torch.from_numpy(sample['face']).float() / 255.0\n",
    "        face = face.permute(2, 0, 1)\n",
    "        if self.augment and np.random.rand() < 0.3:\n",
    "            if np.random.rand() < 0.2:\n",
    "                face = torch.flip(face, [-1])\n",
    "            if np.random.rand() < 0.5:\n",
    "                face = torch.clamp(face * (0.8 + np.random.rand()*0.4), 0, 1)\n",
    "            if np.random.rand() < 0.5:\n",
    "                mean = face.mean(dim=[1, 2], keepdim=True)\n",
    "                face = torch.clamp((face - mean) * (0.9 + np.random.rand()*0.2) + mean, 0, 1)\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        face = normalize(face)\n",
    "\n",
    "        # label\n",
    "        emotion = sample['emotion']\n",
    "        if isinstance(emotion, str):\n",
    "            label = self.emotion_map.get(emotion.lower(), 0)\n",
    "        else:\n",
    "            label = int(emotion)\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
    "            'audio_mel': audio_mel[:, :, :300],\n",
    "            'face': face,\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "def collate_fn(batch, max_audio_length=300):\n",
    "    return {\n",
    "        'input_ids': torch.stack([b['input_ids'] for b in batch]),\n",
    "        'attention_mask': torch.stack([b['attention_mask'] for b in batch]),\n",
    "        'audio_mel': torch.stack([b['audio_mel'] for b in batch]),\n",
    "        'face': torch.stack([b['face'] for b in batch]),\n",
    "        'label': torch.tensor([b['label'] for b in batch])\n",
    "    }\n",
    "\n",
    "# ==================== Training/Eval ====================\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, scheduler=None, grad_clip=5.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        audio_mel = batch['audio_mel'].to(device)\n",
    "        face = batch['face'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                       audio_mel=audio_mel, face=face)\n",
    "        loss = criterion(logits, labels)\n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "        loss.backward()\n",
    "        total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1).detach().cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.3f}', 'grad_norm': f'{float(total_norm):.2f}'})\n",
    "\n",
    "        del input_ids, attention_mask, audio_mel, face, labels, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = total_loss / max(len(dataloader), 1)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        audio_mel = batch['audio_mel'].to(device)\n",
    "        face = batch['face'].to(device)\n",
    "        labels = batch['label'].cpu().numpy()\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                       audio_mel=audio_mel, face=face)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "        del input_ids, attention_mask, audio_mel, face, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return accuracy, f1\n",
    "\n",
    "# ==================== Score functions (as in your first script) ====================\n",
    "def compute_s(probs: np.ndarray, y: int, score_type: str, params=None) -> float:\n",
    "    if params is None: params = {}\n",
    "    if score_type == 'hinge':\n",
    "        return 1 - probs[y]\n",
    "    elif score_type == 'cross_entropy':\n",
    "        return -np.log(probs[y] + 1e-12)\n",
    "    elif score_type == 'margin':\n",
    "        max_other = np.max(np.delete(probs, y))\n",
    "        return max_other - probs[y]\n",
    "    elif score_type == 'raps':\n",
    "        u = params.get('u', 0.1)\n",
    "        lam = params.get('lam', 0.01)\n",
    "        k_reg = params.get('k_reg', 5)\n",
    "        sorted_idx = np.argsort(-probs)\n",
    "        ranks = np.empty(len(probs), int); ranks[sorted_idx] = np.arange(1, len(probs)+1)\n",
    "        R_y = ranks[y]\n",
    "        cumsum = np.sum(probs[sorted_idx[:R_y-1]]) if R_y > 1 else 0.0\n",
    "        s = cumsum + u * probs[y] + lam * max(R_y - k_reg, 0)\n",
    "        return s\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown score_type: {score_type}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_nonconformity_scores(model: nn.Module, loader, device, score_type='hinge', params=None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    scores, labels = [], []\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        audio_mel = batch['audio_mel'].to(device)\n",
    "        face = batch['face'].to(device)\n",
    "        yb = batch['label'].cpu().numpy()\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                       audio_mel=audio_mel, face=face)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "        for i in range(len(yb)):\n",
    "            s = compute_s(probs[i], int(yb[i]), score_type, params)\n",
    "            scores.append(s)\n",
    "        labels.extend(yb)\n",
    "\n",
    "        del input_ids, attention_mask, audio_mel, face, logits\n",
    "        torch.cuda.empty_cache()\n",
    "    return np.array(scores), np.array(labels)\n",
    "\n",
    "def classwise_scores(scores: np.ndarray, labels: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for s, y in zip(scores, labels):\n",
    "        out[int(y)].append(float(s))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "@torch.no_grad()\n",
    "def per_view_pvalues_and_probs(model: nn.Module, class_scores: Dict[int, np.ndarray], loader, L: int, device, score_type='hinge', params=None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    probs_all = []\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        audio_mel = batch['audio_mel'].to(device)\n",
    "        face = batch['face'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                       audio_mel=audio_mel, face=face)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "        probs_all.append(probs)\n",
    "\n",
    "        del input_ids, attention_mask, audio_mel, face, logits\n",
    "        torch.cuda.empty_cache()\n",
    "    probs_all = np.vstack(probs_all)  # (n, L)\n",
    "\n",
    "    n = probs_all.shape[0]\n",
    "    pvals = np.zeros((n, L))\n",
    "    for i in range(n):\n",
    "        for y in range(L):\n",
    "            s_y = compute_s(probs_all[i], y, score_type, params)\n",
    "            cal = class_scores.get(y, np.array([]))\n",
    "            if cal.size == 0:\n",
    "                pvals[i, y] = 1.0\n",
    "            else:\n",
    "                counts = np.sum(cal >= s_y)\n",
    "                pvals[i, y] = (1 + counts) / (len(cal) + 1)\n",
    "    return pvals, probs_all\n",
    "\n",
    "# ==================== Fusion utilities ====================\n",
    "def build_fusion_features(pvals_list: List[np.ndarray], probs_list: List[np.ndarray]) -> np.ndarray:\n",
    "    blocks = [np.hstack([pvals_list[k], probs_list[k]]) for k in range(len(pvals_list))]\n",
    "    return np.hstack(blocks)\n",
    "\n",
    "def min_p_value_fusion(P_all: np.ndarray) -> np.ndarray:\n",
    "    K = P_all.shape[0]\n",
    "    return K * np.min(P_all, axis=0)\n",
    "\n",
    "def fisher_fusion(P_all: np.ndarray) -> np.ndarray:\n",
    "    eps = 1e-12\n",
    "    p = np.clip(P_all, eps, 1.0)\n",
    "    T = -2 * np.sum(np.log(p), axis=0)\n",
    "    df = 2 * P_all.shape[0]\n",
    "    return 1 - chi2.cdf(T, df=df)\n",
    "\n",
    "def adjusted_fisher_fusion(P_train: np.ndarray, y_train: np.ndarray, P_test: np.ndarray, L: int) -> np.ndarray:\n",
    "    K, _, _ = P_train.shape\n",
    "    n_test = P_test.shape[1]\n",
    "    eps = 1e-12\n",
    "    out = np.zeros((n_test, L))\n",
    "    for y in range(L):\n",
    "        idx = np.where(y_train == y)[0]\n",
    "        if idx.size < 5:\n",
    "            out[:, y] = fisher_fusion(P_test)[:, y]\n",
    "            continue\n",
    "        P_cls = np.clip(P_train[:, idx, y], eps, 1.0)  # (K, n_y)\n",
    "        W = -2 * np.log(P_cls)                          # (K, n_y)\n",
    "        Wc = W - W.mean(axis=1, keepdims=True)\n",
    "        Sigma = (Wc @ Wc.T) / max(W.shape[1] - 1, 1)    # (K, K)\n",
    "        var_T = np.sum(Sigma)\n",
    "        if not np.isfinite(var_T) or var_T <= 0:\n",
    "            var_T = 4 * K\n",
    "        f_y = (8.0 * K * K) / var_T\n",
    "        c_y = var_T / (4 * K)\n",
    "        P_t = np.clip(P_test[:, :, y], eps, 1.0)\n",
    "        T_t = -2 * np.sum(np.log(P_t), axis=0)\n",
    "        out[:, y] = 1 - chi2.cdf(T_t / c_y, df=f_y)\n",
    "    return out\n",
    "\n",
    "def weighted_average_fusion(P_all: np.ndarray, weights: np.ndarray) -> np.ndarray:\n",
    "    return np.tensordot(weights, P_all, axes=(0, 0))\n",
    "\n",
    "def learn_view_weights_from_pvals(pv_train_concat: np.ndarray, y_train: np.ndarray, K: int, L: int, max_iter: int, seed: int) -> np.ndarray:\n",
    "    lr = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=max_iter, random_state=seed)\n",
    "    lr.fit(pv_train_concat, y_train)\n",
    "    B = lr.coef_  # (L, K*L)\n",
    "    imps = []\n",
    "    for k in range(K):\n",
    "        block = B[:, k*L:(k+1)*L]\n",
    "        imps.append(np.linalg.norm(block, ord=\"fro\"))\n",
    "    w = np.array(imps, float)\n",
    "    w = np.maximum(w, 1e-12)\n",
    "    return w / w.sum()\n",
    "\n",
    "def fused_class_cal_scores(y_cal: np.ndarray, fused_probs_cal: np.ndarray, L: int) -> Dict[int, np.ndarray]:\n",
    "    s = 1 - fused_probs_cal[np.arange(len(y_cal)), y_cal]\n",
    "    out = {c: [] for c in range(L)}\n",
    "    for sc, yy in zip(s, y_cal):\n",
    "        out[int(yy)].append(float(sc))\n",
    "    return {c: np.asarray(v, float) for c, v in out.items()}\n",
    "\n",
    "def fused_p_values_from_cal(fused_probs: np.ndarray, cal_class_scores: Dict[int, np.ndarray]) -> np.ndarray:\n",
    "    n, L = fused_probs.shape\n",
    "    out = np.zeros((n, L))\n",
    "    for y in range(L):\n",
    "        cal = cal_class_scores.get(y, np.array([]))\n",
    "        if cal.size == 0:\n",
    "            out[:, y] = 1.0\n",
    "        else:\n",
    "            s_test = 1 - fused_probs[:, y]\n",
    "            counts = np.sum(cal[:, None] >= s_test[None, :], axis=0)\n",
    "            out[:, y] = (1 + counts) / (len(cal) + 1)\n",
    "    return out\n",
    "\n",
    "def evaluate_sets(P: np.ndarray, y_true: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    C = (P > alpha)\n",
    "    cov = float(np.mean(C[np.arange(len(y_true)), y_true]))\n",
    "    size = float(np.mean(C.sum(axis=1)))\n",
    "    return cov, size\n",
    "\n",
    "# ==================== Utility: recompute probs on a loader ====================\n",
    "@torch.no_grad()\n",
    "def compute_probs_mm(model: nn.Module, loader, device) -> np.ndarray:\n",
    "    model.eval()\n",
    "    probs_all = []\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        audio_mel = batch['audio_mel'].to(device)\n",
    "        face = batch['face'].to(device)\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                       audio_mel=audio_mel, face=face)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "        probs_all.append(probs)\n",
    "        del input_ids, attention_mask, audio_mel, face, logits\n",
    "        torch.cuda.empty_cache()\n",
    "    return np.vstack(probs_all)\n",
    "\n",
    "# ==================== Summaries ====================\n",
    "def summarize_table(df: pd.DataFrame, methods: List[str], metric_name: str) -> pd.DataFrame:\n",
    "    g = df.groupby([\"Score\", \"K\"]).agg({m: [\"mean\", \"std\"] for m in methods})\n",
    "    g.columns = [f\"{a}_{b}\" for a, b in g.columns]\n",
    "    g = g.reset_index()\n",
    "    for m in methods:\n",
    "        g[m] = g.apply(lambda r: f\"{r[f'{m}_mean']:.2f} ({r[f'{m}_std']:.2f})\", axis=1)\n",
    "    g.insert(2, \"Metric\", metric_name)\n",
    "    return g[[\"Score\", \"K\", \"Metric\"] + methods]\n",
    "\n",
    "# ==================== Config ====================\n",
    "@dataclass\n",
    "class MELDConfig:\n",
    "    alpha: float = 0.1\n",
    "    Ks: Tuple[int, ...] = (3,)\n",
    "    num_classes: int = 7\n",
    "    num_simulations: int = 10\n",
    "\n",
    "    epochs_text: int = 10\n",
    "    epochs_audio: int = 20\n",
    "    epochs_video: int = 20\n",
    "\n",
    "    lr_text: float = 5e-5\n",
    "    lr_audio: float = 1e-3\n",
    "    lr_video: float = 1e-3\n",
    "\n",
    "    batch_size: int = 64\n",
    "    inference_batch_size: int = 8\n",
    "    warmup_ratio: float = 0.15\n",
    "    max_iter_lr: int = 1000\n",
    "    train_seed_base: int = 40\n",
    "    weight_decay: float = 0.01\n",
    "    label_smoothing: float = 0.0\n",
    "    grad_clip: float = 5.0\n",
    "    patience: int = 3\n",
    "\n",
    "    train_frac: float = 0.6\n",
    "    cal_frac_of_temp: float = 0.2\n",
    "    fuse_train_frac_of_rest: float = 0.5\n",
    "\n",
    "# ==================== Main experiment ====================\n",
    "def run_experiments(cfg: MELDConfig):\n",
    "    results_cov, results_size, results_acc = [], [], []\n",
    "    global device, tokenizer, full_train_files, test_files, Y_full, Y_test\n",
    "\n",
    "    # Score functions to match your first code\n",
    "    score_types = {\n",
    "        'hinge': {},\n",
    "        'margin': {},\n",
    "        'cross_entropy': {},\n",
    "        'raps': {'u': 0.1, 'lam': 0.01, 'k_reg': 5}\n",
    "    }\n",
    "\n",
    "    for sim in range(cfg.num_simulations):\n",
    "        print(f\"\\n{'='*60}\\nSimulation {sim+1}/{cfg.num_simulations}\\n{'='*60}\")\n",
    "        seed = cfg.train_seed_base + sim\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "        rng = np.random.RandomState(seed)\n",
    "\n",
    "        # Stratified splits on file indices\n",
    "        indices = np.arange(len(full_train_files))\n",
    "        trP_idx, tmp_idx = train_test_split(indices, test_size=1 - cfg.train_frac, stratify=Y_full, random_state=seed)\n",
    "        cal_idx, rest_idx = train_test_split(tmp_idx, test_size=1 - cfg.cal_frac_of_temp, stratify=Y_full[tmp_idx], random_state=seed)\n",
    "        ftr_idx, fcal_idx = train_test_split(rest_idx, test_size=1 - cfg.fuse_train_frac_of_rest, stratify=Y_full[rest_idx], random_state=seed)\n",
    "\n",
    "        X_trP_files = [full_train_files[i] for i in trP_idx]\n",
    "        X_cal_files = [full_train_files[i] for i in cal_idx]\n",
    "        X_fuse_tr_files = [full_train_files[i] for i in ftr_idx]\n",
    "        X_fuse_cal_files = [full_train_files[i] for i in fcal_idx]\n",
    "        X_te_files = test_files\n",
    "\n",
    "        y_trP = Y_full[trP_idx]\n",
    "        y_cal = Y_full[cal_idx]\n",
    "        y_fuse_tr = Y_full[ftr_idx]\n",
    "        y_fuse_cal = Y_full[fcal_idx]\n",
    "        y_te = Y_test\n",
    "\n",
    "        # Datasets / loaders\n",
    "        train_dataset = PreprocessedMELDDataset(None, tokenizer, files=X_trP_files, augment=False)\n",
    "        cal_dataset = PreprocessedMELDDataset(None, tokenizer, files=X_cal_files, augment=False)\n",
    "        ftr_dataset = PreprocessedMELDDataset(None, tokenizer, files=X_fuse_tr_files, augment=False)\n",
    "        fcal_dataset = PreprocessedMELDDataset(None, tokenizer, files=X_fuse_cal_files, augment=False)\n",
    "        te_dataset = PreprocessedMELDDataset(None, tokenizer, files=X_te_files, augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True,\n",
    "                                  collate_fn=lambda b: collate_fn(b, 300), num_workers=4, pin_memory=True, drop_last=True)\n",
    "        cal_loader = DataLoader(cal_dataset, batch_size=cfg.inference_batch_size, shuffle=False,\n",
    "                                collate_fn=lambda b: collate_fn(b, 300), num_workers=4, pin_memory=True)\n",
    "        ftr_loader = DataLoader(ftr_dataset, batch_size=cfg.inference_batch_size, shuffle=False,\n",
    "                                collate_fn=lambda b: collate_fn(b, 300), num_workers=4, pin_memory=True)\n",
    "        fcal_loader = DataLoader(fcal_dataset, batch_size=cfg.inference_batch_size, shuffle=False,\n",
    "                                 collate_fn=lambda b: collate_fn(b, 300), num_workers=4, pin_memory=True)\n",
    "        te_loader = DataLoader(te_dataset, batch_size=cfg.inference_batch_size, shuffle=False,\n",
    "                               collate_fn=lambda b: collate_fn(b, 300), num_workers=4, pin_memory=True)\n",
    "\n",
    "        # Train per-view models once\n",
    "        view_model_classes = [ImprovedTextModel, ImprovedAudioModel, ImprovedVideoModel]\n",
    "        learning_rates = [cfg.lr_text, cfg.lr_audio, cfg.lr_video]\n",
    "        model_names = [\"Text (RoBERTa)\", \"Audio (CNN)\", \"Video (ResNet34)\"]\n",
    "        epochs_per_model = [cfg.epochs_text, cfg.epochs_audio, cfg.epochs_video]\n",
    "\n",
    "        per_view_models = []\n",
    "        pr_te_allviews = []  # test probs (for per-score fusion/accuracy)\n",
    "        for v in range(3):\n",
    "            print(f\"\\n [{model_names[v]}] Training...\")\n",
    "            m = view_model_classes[v](num_classes=cfg.num_classes).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            if v == 0:\n",
    "                base_params = [p for n, p in m.named_parameters() if 'text_encoder.encoder.layer' in n]\n",
    "                other_params = [p for n, p in m.named_parameters() if 'text_encoder.encoder.layer' not in n]\n",
    "                optimizer = torch.optim.AdamW([\n",
    "                    {'params': base_params, 'lr': learning_rates[v]},\n",
    "                    {'params': other_params, 'lr': learning_rates[v] * 10}\n",
    "                ], weight_decay=cfg.weight_decay)\n",
    "            elif v == 1:\n",
    "                optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rates[v], weight_decay=cfg.weight_decay)\n",
    "            else:\n",
    "                trainable_params = [p for p in m.parameters() if p.requires_grad]\n",
    "                optimizer = torch.optim.AdamW(trainable_params, lr=learning_rates[v], weight_decay=cfg.weight_decay)\n",
    "\n",
    "            total_steps = epochs_per_model[v] * len(train_loader)\n",
    "            warmup_steps = int(total_steps * cfg.warmup_ratio)\n",
    "            scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "            best_f1, best_acc, best_state, patience_counter = 0.0, 0.0, None, 0\n",
    "            for epoch in range(epochs_per_model[v]):\n",
    "                train_loss, train_acc, train_f1 = train_epoch(\n",
    "                    m, train_loader, optimizer, criterion, device,\n",
    "                    scheduler=scheduler, grad_clip=cfg.grad_clip\n",
    "                )\n",
    "                val_acc, val_f1 = evaluate(m, cal_loader, device)\n",
    "                if val_f1 > best_f1:\n",
    "                    best_f1, best_acc = val_f1, val_acc\n",
    "                    patience_counter = 0\n",
    "                    best_state = {k: vv.cpu() for k, vv in m.state_dict().items()}\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                print(f\" Epoch {epoch+1:2d}/{epochs_per_model[v]}: \"\n",
    "                      f\"Loss={train_loss:.3f}, Train Acc={train_acc*100:.1f}%, F1={train_f1:.3f} | \"\n",
    "                      f\"Val Acc={val_acc*100:.1f}%, F1={val_f1:.3f} | Best F1={best_f1:.3f}\")\n",
    "\n",
    "                if patience_counter >= cfg.patience:\n",
    "                    print(\" Early stopping\")\n",
    "                    break\n",
    "\n",
    "            if best_state is not None:\n",
    "                m.load_state_dict(best_state)\n",
    "            print(f\" [{model_names[v]}] Best Val: Acc={best_acc*100:.2f}%, F1={best_f1:.4f}\")\n",
    "            m.eval()\n",
    "\n",
    "            # Compute test probs once and cache\n",
    "            _, pr_te_v = per_view_pvalues_and_probs(m, {}, te_loader, cfg.num_classes, device, score_type='hinge', params={})\n",
    "            pr_te_allviews.append(pr_te_v)\n",
    "            per_view_models.append(m)\n",
    "\n",
    "            del optimizer, scheduler, criterion, best_state\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "        # ===== Loop over score functions (like your first script) =====\n",
    "        for score_name, score_params in score_types.items():\n",
    "            print(f\"\\n{'-'*60}\\nScore Function: {score_name}\\n{'-'*60}\")\n",
    "\n",
    "            pv_tr, pr_tr = [], []\n",
    "            pv_cal, pr_cal = [], []\n",
    "            pv_te_list = []\n",
    "            cal_classwise = []\n",
    "\n",
    "            # Per-view conformal calibration per score\n",
    "            for v in range(3):\n",
    "                m = per_view_models[v]\n",
    "                m.to(device)\n",
    "                m.eval()\n",
    "\n",
    "                # Calibration nonconformity scores\n",
    "                sc, lab = compute_nonconformity_scores(m, cal_loader, device, score_type=score_name, params=score_params)\n",
    "                cal_classwise_v = classwise_scores(sc, lab, cfg.num_classes)\n",
    "                cal_classwise.append(cal_classwise_v)\n",
    "\n",
    "                # p/probs on fuse-train / fuse-cal / test\n",
    "                p_tr, pr_tr_v = per_view_pvalues_and_probs(m, cal_classwise_v, ftr_loader, cfg.num_classes, device, score_type=score_name, params=score_params)\n",
    "                pv_tr.append(p_tr); pr_tr.append(pr_tr_v)\n",
    "\n",
    "                p_cal, pr_cal_v = per_view_pvalues_and_probs(m, cal_classwise_v, fcal_loader, cfg.num_classes, device, score_type=score_name, params=score_params)\n",
    "                pv_cal.append(p_cal); pr_cal.append(pr_cal_v)\n",
    "\n",
    "                p_te, _ = per_view_pvalues_and_probs(m, cal_classwise_v, te_loader, cfg.num_classes, device, score_type=score_name, params=score_params)\n",
    "                pv_te_list.append(p_te)\n",
    "\n",
    "                # keep model on CPU after\n",
    "                m.to('cpu')\n",
    "\n",
    "                del sc, lab, p_tr, pr_tr_v, p_cal, pr_cal_v, p_te, cal_classwise_v\n",
    "                torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "            # ===== Conformal Fusion and baselines =====\n",
    "            print(\" Training fusion model...\")\n",
    "            X_ftr = build_fusion_features(pv_tr, pr_tr)\n",
    "            fusion_lr = LogisticRegression(max_iter=cfg.max_iter_lr, multi_class=\"multinomial\",\n",
    "                                           solver=\"lbfgs\", random_state=seed)\n",
    "            fusion_lr.fit(X_ftr, y_fuse_tr)\n",
    "\n",
    "            X_fcal = build_fusion_features(pv_cal, pr_cal)\n",
    "            fused_probs_cal = fusion_lr.predict_proba(X_fcal)\n",
    "            fused_cal_scores = fused_class_cal_scores(y_fuse_cal, fused_probs_cal, cfg.num_classes)\n",
    "\n",
    "            X_ftest = build_fusion_features(pv_te_list, pr_te_allviews)\n",
    "            fused_probs_test = fusion_lr.predict_proba(X_ftest)\n",
    "            P_cf = fused_p_values_from_cal(fused_probs_test, fused_cal_scores)\n",
    "\n",
    "            # Baselines on stacked per-view pvals\n",
    "            P_train = np.stack(pv_tr, axis=0)\n",
    "            P_test = np.stack(pv_te_list, axis=0)\n",
    "            P_min = min_p_value_fusion(P_test)\n",
    "            P_fisher = fisher_fusion(P_test)\n",
    "            P_adjF = adjusted_fisher_fusion(P_train, y_fuse_tr, P_test, cfg.num_classes)\n",
    "\n",
    "            pv_tr_concat = np.concatenate(pv_tr, axis=1)\n",
    "            w_learned = learn_view_weights_from_pvals(pv_tr_concat, y_fuse_tr, 3, cfg.num_classes, cfg.max_iter_lr, seed)\n",
    "            P_wavgL = weighted_average_fusion(P_test, w_learned)\n",
    "\n",
    "            # Evaluate all methods\n",
    "            cov_cf, set_cf = evaluate_sets(P_cf, y_te, cfg.alpha)\n",
    "            cov_min, set_min = evaluate_sets(P_min, y_te, cfg.alpha)\n",
    "            cov_fi, set_fi = evaluate_sets(P_fisher, y_te, cfg.alpha)\n",
    "            cov_afi, set_afi = evaluate_sets(P_adjF, y_te, cfg.alpha)\n",
    "            cov_wl, set_wl = evaluate_sets(P_wavgL, y_te, cfg.alpha)\n",
    "\n",
    "            # Accuracies\n",
    "            avg_probs = np.mean(np.stack(pr_te_allviews, axis=0), axis=0)\n",
    "            fused_acc = accuracy_score(y_te, np.argmax(fused_probs_test, axis=1)) * 100\n",
    "            avg_acc = accuracy_score(y_te, np.argmax(avg_probs, axis=1)) * 100\n",
    "            view_accs = [accuracy_score(y_te, np.argmax(pr_te_allviews[v], axis=1)) * 100 for v in range(3)]\n",
    "\n",
    "            print(f\"\\n Results Summary ({score_name}):\")\n",
    "            print(f\" {'='*50}\")\n",
    "            print(f\" Individual Accuracies:\")\n",
    "            print(f\" Text:  {view_accs[0]:5.2f}% | Audio: {view_accs[1]:5.2f}% | Video: {view_accs[2]:5.2f}%\")\n",
    "            print(f\" Fusion Accuracies: Avg Ensemble {avg_acc:5.2f}% | Learned Fusion {fused_acc:5.2f}%\")\n",
    "            print(f\" Conformal Metrics (target {100*(1-cfg.alpha):.0f}%):\")\n",
    "            print(f\" CF:     cov={cov_cf*100:5.2f}% | set={set_cf:5.2f}\")\n",
    "            print(f\" MinPV:  cov={cov_min*100:5.2f}% | set={set_min:5.2f}\")\n",
    "            print(f\" Fisher: cov={cov_fi*100:5.2f}% | set={set_fi:5.2f}\")\n",
    "            print(f\" AdjFis: cov={cov_afi*100:5.2f}% | set={set_afi:5.2f}\")\n",
    "            print(f\" WAvgL:  cov={cov_wl*100:5.2f}% | set={set_wl:5.2f}\")\n",
    "            print(f\" {'='*50}\")\n",
    "\n",
    "            # Append results\n",
    "            results_cov.append({\n",
    "                \"Score\": score_name, \"Sim\": sim, \"K\": 3,\n",
    "                \"Conformal Fusion\": cov_cf * 100,\n",
    "                \"Min p-Value\": cov_min * 100,\n",
    "                \"Fisher\": cov_fi * 100,\n",
    "                \"Adjusted Fisher\": cov_afi * 100,\n",
    "                \"Weighted Avg (learned)\": cov_wl * 100,\n",
    "            })\n",
    "            results_size.append({\n",
    "                \"Score\": score_name, \"Sim\": sim, \"K\": 3,\n",
    "                \"Conformal Fusion\": set_cf,\n",
    "                \"Min p-Value\": set_min,\n",
    "                \"Fisher\": set_fi,\n",
    "                \"Adjusted Fisher\": set_afi,\n",
    "                \"Weighted Avg (learned)\": set_wl,\n",
    "            })\n",
    "            results_acc.append({\n",
    "                \"Score\": score_name, \"Sim\": sim, \"K\": 3,\n",
    "                \"Fused Acc\": fused_acc,\n",
    "                \"Average Acc\": avg_acc,\n",
    "                \"Text Acc\": view_accs[0],\n",
    "                \"Audio Acc\": view_accs[1],\n",
    "                \"Video Acc\": view_accs[2]\n",
    "            })\n",
    "\n",
    "            # cleanup per-score\n",
    "            del X_ftr, fusion_lr, X_fcal, fused_probs_cal, fused_cal_scores, X_ftest, fused_probs_test, P_cf\n",
    "            del P_train, P_test, P_min, P_fisher, P_adjF, pv_tr_concat, w_learned, P_wavgL\n",
    "            torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "        # cleanup per simulation\n",
    "        for m in per_view_models:\n",
    "            m.to('cpu')\n",
    "            del m\n",
    "        del per_view_models, pr_te_allviews\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    return pd.DataFrame(results_cov), pd.DataFrame(results_size), pd.DataFrame(results_acc)\n",
    "\n",
    "# ==================== Save + print ====================\n",
    "def save_tables(df_cov: pd.DataFrame, df_size: pd.DataFrame, df_acc: pd.DataFrame):\n",
    "    methods = [\n",
    "        \"Conformal Fusion\",\n",
    "        \"Min p-Value\",\n",
    "        \"Fisher\",\n",
    "        \"Adjusted Fisher\",\n",
    "        \"Weighted Avg (learned)\",\n",
    "    ]\n",
    "    sum_cov = summarize_table(df_cov, methods, \"Coverage (%)\")\n",
    "    sum_set = summarize_table(df_size, methods, \"Average Set Size\")\n",
    "\n",
    "    sum_cov.to_csv(\"meld_summary_coverage.csv\", index=False)\n",
    "    sum_set.to_csv(\"meld_summary_setsize.csv\", index=False)\n",
    "    with open(\"meld_summary_coverage.tex\", \"w\") as f:\n",
    "        f.write(sum_cov.to_latex(index=False, escape=False))\n",
    "    with open(\"meld_summary_setsize.tex\", \"w\") as f:\n",
    "        f.write(sum_set.to_latex(index=False, escape=False))\n",
    "\n",
    "    cov_comp = sum_cov.drop(columns=[\"Metric\"]).rename(columns={\n",
    "        \"Conformal Fusion\": \"CF Cov\",\n",
    "        \"Min p-Value\": \"MinPV Cov\",\n",
    "        \"Fisher\": \"Fisher Cov\",\n",
    "        \"Adjusted Fisher\": \"AdjF Cov\",\n",
    "        \"Weighted Avg (learned)\": \"WAvgL Cov\",\n",
    "    })\n",
    "    set_comp = sum_set.drop(columns=[\"Metric\"]).rename(columns={\n",
    "        \"Conformal Fusion\": \"CF Set\",\n",
    "        \"Min p-Value\": \"MinPV Set\",\n",
    "        \"Fisher\": \"Fisher Set\",\n",
    "        \"Adjusted Fisher\": \"AdjF Set\",\n",
    "        \"Weighted Avg (learned)\": \"WAvgL Set\",\n",
    "    })\n",
    "    final = cov_comp.merge(set_comp, on=[\"Score\", \"K\"]).sort_values([\"Score\", \"K\"])\n",
    "    final.to_csv(\"meld_summary_final.csv\", index=False)\n",
    "    with open(\"meld_summary_final.tex\", \"w\") as f:\n",
    "        f.write(final.to_latex(index=False, escape=False))\n",
    "\n",
    "    acc_summary = df_acc.groupby([\"Score\", \"K\"]).agg({\n",
    "        \"Fused Acc\": [\"mean\", \"std\"],\n",
    "        \"Average Acc\": [\"mean\", \"std\"],\n",
    "        \"Text Acc\": [\"mean\", \"std\"],\n",
    "        \"Audio Acc\": [\"mean\", \"std\"],\n",
    "        \"Video Acc\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "    acc_summary.columns = ['Score', 'K'] + [f\"{col[0]}_{col[1]}\" if col[1] else col[0]\n",
    "                                   for col in acc_summary.columns[2:]]\n",
    "    acc_summary.to_csv(\"meld_accuracy_summary.csv\", index=False)\n",
    "    with open(\"meld_accuracy_summary.tex\", \"w\") as f:\n",
    "        f.write(acc_summary.to_latex(index=False, float_format=\"%.2f\"))\n",
    "\n",
    "    print(\"\\nSaved:\")\n",
    "    print(\" - meld_summary_coverage.csv/tex\")\n",
    "    print(\" - meld_summary_setsize.csv/tex\")\n",
    "    print(\" - meld_summary_final.csv/tex\")\n",
    "    print(\" - meld_accuracy_summary.csv/tex\")\n",
    "\n",
    "# ==================== Setup / Dataset loading ====================\n",
    "def setup_environment():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\"); print(\"Using MPS device\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\"); print(\"Using CPU device\")\n",
    "    print(\"Loading RoBERTa tokenizer...\")\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    return device, tokenizer\n",
    "\n",
    "def load_dataset_labels(data_dir: str):\n",
    "    emotion_map = {'neutral': 0, 'joy': 1, 'surprise': 2, 'anger': 3, 'sadness': 4, 'disgust': 5, 'fear': 6}\n",
    "    print(f\"\\nLoading data from: {data_dir}\")\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    dev_dir = os.path.join(data_dir, 'dev')\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "    train_files = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.endswith('.pt')]\n",
    "    dev_files = [os.path.join(dev_dir, f) for f in os.listdir(dev_dir) if f.endswith('.pt')]\n",
    "    test_files = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith('.pt')]\n",
    "\n",
    "    full_train_files = sorted(train_files + dev_files)\n",
    "    test_files = sorted(test_files)\n",
    "\n",
    "    print(\"Loading labels for stratification...\")\n",
    "    Y_full = []\n",
    "    for f in tqdm(full_train_files, desc=\"Loading train labels\"):\n",
    "        sample = torch.load(f, map_location='cpu')\n",
    "        emotion = sample['emotion'].lower() if isinstance(sample['emotion'], str) else str(sample['emotion'])\n",
    "        Y_full.append(emotion_map.get(emotion, 0))\n",
    "    Y_full = np.array(Y_full)\n",
    "\n",
    "    Y_test = []\n",
    "    for f in tqdm(test_files, desc=\"Loading test labels\"):\n",
    "        sample = torch.load(f, map_location='cpu')\n",
    "        emotion = sample['emotion'].lower() if isinstance(sample['emotion'], str) else str(sample['emotion'])\n",
    "        Y_test.append(emotion_map.get(emotion, 0))\n",
    "    Y_test = np.array(Y_test)\n",
    "\n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\" Train samples: {len(Y_full)}\")\n",
    "    print(f\" Test samples:  {len(Y_test)}\")\n",
    "    emotion_names = ['neutral', 'joy', 'surprise', 'anger', 'sadness', 'disgust', 'fear']\n",
    "    for i, emotion in enumerate(emotion_names):\n",
    "        count = np.sum(Y_full == i)\n",
    "        print(f\" {emotion:10s}: {count:4d} ({count/len(Y_full)*100:.1f}%)\")\n",
    "    return full_train_files, test_files, Y_full, Y_test\n",
    "\n",
    "# ==================== Entry ====================\n",
    "device = None\n",
    "tokenizer = None\n",
    "full_train_files = None\n",
    "test_files = None\n",
    "Y_full = None\n",
    "Y_test = None\n",
    "\n",
    "def main():\n",
    "    global device, tokenizer, full_train_files, test_files, Y_full, Y_test\n",
    "    device, tokenizer = setup_environment()\n",
    "\n",
    "    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    # TODO: set to your preprocessed MELD root (with train/dev/test)\n",
    "    DATA_DIR = '/depot/gupta869/data/farbod/preprocessed_data'\n",
    "    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "    full_train_files, test_files, Y_full, Y_test = load_dataset_labels(DATA_DIR)\n",
    "\n",
    "    cfg = MELDConfig()\n",
    "    print(f\"\\nExperiment Configuration:\")\n",
    "    print(f\" Device: {device}\")\n",
    "    print(f\" Epochs: Text={cfg.epochs_text}, Audio={cfg.epochs_audio}, Video={cfg.epochs_video}\")\n",
    "    print(f\" LRs:    Text={cfg.lr_text}, Audio={cfg.lr_audio}, Video={cfg.lr_video}\")\n",
    "    print(f\" Batch size: {cfg.batch_size} (train), {cfg.inference_batch_size} (inf)\")\n",
    "    print(f\" Weight decay: {cfg.weight_decay} | Label smoothing: {cfg.label_smoothing}\")\n",
    "    print(f\" Sims: {cfg.num_simulations}\")\n",
    "\n",
    "    df_cov, df_size, df_acc = run_experiments(cfg)\n",
    "\n",
    "    print(\"\\n=== Coverage (raw rows) ===\")\n",
    "    print(df_cov.head())\n",
    "    print(\"\\n=== Set Size (raw rows) ===\")\n",
    "    print(df_size.head())\n",
    "    print(\"\\n=== Accuracy (raw rows) ===\")\n",
    "    print(df_acc.head())\n",
    "\n",
    "    save_tables(df_cov, df_size, df_acc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c57d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
